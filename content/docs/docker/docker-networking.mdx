---
title: Сеть и изоляция
---
## Вопросы

### Каким образом в Docker реализована изоляция контейнеров (namespace)?

Докер используется namespaces. Для создания изолированного рабочего пространства, которое называется контейнером.
При запуске контейнера докер создает набор неймспейсов для этого контейнера.

Эти неймспейсы обеспечивают уровень изоляции. Каждый аспект контейнера выполняется в отдельном контейнере и его доступ ограничен неймспейсом.

В частности в Docker Engine использует следующее:
- Пространство имен pid: Изоляция процессов (PID: идентификатор процесса).
- Пространство имен net: Управление сетевыми интерфейсами (NET: Networking).
- Пространство имен ipc: Управление доступом к ресурсам IPC (IPC: InterProcess Communication).
- Пространство имен mnt: Управление точками монтирования файловой системы (MNT: Mount).
- Пространство имен uts: Изолирование идентификаторов ядра и версий. (UTS: Unix Timesharing System).

### Почему в контейнере видно только свои процессы?

Это связано с тем, что Docker использует пространство имен PID (Process ID) для обеспечения изоляции процессов в контейнерах.
Когда создается новый контейнер, Docker создает новое пространство имен PID для этого контейнера и запускает процесс в этом пространстве имен.

В этом изолированном пространстве имен PID относится только к процессам, запущенным в том же контейнере.  
Это означает, что процесс в контейнере **может видеть только другие процессы в том же контейнере и не имеет возможности видеть процессы, запущенные в других контейнерах или на хост-системе**.
Это ключевой аспект изоляции и безопасности, обеспечиваемой контейнерами Docker.

### Какие типы сетей есть в Docker?

**bridge** - Это стандартная сеть по умолчанию, которая создает виртуальный мост (bridge) для обмена данными между контейнерами. Каждый контейнер получает собственный IP-адрес из диапазона сети Docker.

**host** - использует сетевой стек хоста, что означает, что контейнеры не изолированы на уровне сети от хоста. То есть, контейнер не изолирован по портам и делает запросы напрямую через сеть хоста.

**none** - контейнер не имеет доступа к сети.

**overlays** - тип сетей которые пересекают несколько узлов. Полезно когда у тебя docker контейнеры запушенны на разных хостах, но они должны общаться между собой. Для реализации этой сети Docker использует технологии, такие как **VXLAN** (Virtual Extensible LAN).

### Можно ли настроить сетевое взаимодействие между контейнерами? Как реализовано?

Можно.
- Контейнеры должны быть частью одной сети
- Докер создает виртуальную сеть, default bridge и подключает к ней контейнеры. Также, использует драйвер overlay для многохостовых сетей
- В сети контейнерам назначается айпишник
- Если контейнеры имеют выход в большую сеть, то они ведут себя как программы на отдельных компах

Пример с сетевым драйвером bridge:

1. Создаем сеть
```
docker network create my_network
```

2. Запускаем два контейнера в сети (sleep 1d это для бездействия контейнера в течение дня. Полезно при дебаге порой):
```
docker run -d --name container1 --network my_network alpine sleep 1d
docker run -d --name container2 --network my_network alpine sleep 1d
```

3. Пробуем попинговать по имени:
```
docker exec -it container1 ping container2
ubuntu@host:~$ docker exec -it container1 ping container2
PING container2 (172.18.0.3): 56 data bytes
64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.110 ms
64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.083 ms
64 bytes from 172.18.0.3: seq=2 ttl=64 time=0.111 ms
```

 Это работает потому, что когда вы создаете контейнер в сети Docker, он получает собственный IP-адрес в этой сети и добавляет DNS-запись на DNS-сервер сети.
 Это позволяет контейнерам в одной сети взаимодействовать друг с другом, используя свои имена.
 Если вы хотите создать сеть на нескольких хостах Docker, используйте сетевой драйвер `overlay`.  
 Для этого потребуется Docker Swarm или стороннее хранилище ключевых значений, например Consul или etcd.

### Какие типы сетевых драйверов используются в docker?

Основные драйвера сетей docker: bridge, host, overlay, ipvlan, macvlan, none

**bridge:** это сетевой драйвер по умолчанию. Бридж сеть используется, когда ваши приложения запускаются в автономных контейнерах, которые должны взаимодействовать между собой.

Взаимодействие с хостом выполняется через мост docker0 и конфигурацию таблицы iptables nat. В этом режиме будет выделено сетевое пространство имен, задан IP-адрес для каждого контейнера, а контейнер Docker на хосте будет подключен к виртуальному мосту. Виртуальный мост работает как физический коммутатор, поэтому все контейнеры на хосте подключены к сети уровня 2 через коммутатор.

**host:** использует сеть хоста напрямую без изоляции контейнера и хоста.

**none:** этот режим помещает контейнер в свой собственный сетевой стек, но не выполняет никакой настройки. Фактически, этот режим отключает сетевую функцию контейнера, что полезно в следующих двух ситуациях: контейнер не требует сети (например, только для пакетной задачи записи дисковых томов).

**macvlan:** в режиме Macvlan Bridge каждый контейнер имеет уникальный MAC-адрес, который используется для отслеживания сопоставления MAC-адреса с портом хоста Docker. Сеть драйвера Macvlan подключается к родительскому интерфейсу хоста Docker. Примерами являются физические интерфейсы, такие как eth0, субинтерфейс eth0.10 для тегирования VLAN 802.1q (.10 означает VLAN 10) или даже связанный хост-адаптер, который объединяет два интерфейса Ethernet в единый логический интерфейс. Назначенный шлюз является внешним по отношению к хосту, предоставляемому сетевой инфраструктурой. Каждая сеть Docker в режиме Macvlan Bridge изолирована друг от друга, и только одна сеть может быть подключена к родительскому узлу одновременно. Каждый хост-адаптер имеет теоретический предел, и каждый хост-адаптер может подключаться к сети Docker. Любой контейнер в той же подсети может взаимодействовать с любым другим контейнером в той же сети без шлюзового моста macvlan. Та же сетевая команда docker применяется к драйверу vlan. В режиме Macvlan без внешней маршрутизации процессов между двумя сетями / подсетями контейнеры в разных сетях не могут получить доступ друг к другу. Это также относится к нескольким подсетям в одной и той же терминальной сети.

**overlay:** Оверлейные сети соединяют несколько демонов Docker вместе и позволяют сервисам swarm взаимодействовать друг с другом. Вы также можете использовать оверлейные сети для облегчения связи между сервисом swarm и автономным контейнером или между двумя автономными контейнерами в разных демонах Docker. Эта стратегия устраняет необходимость выполнять маршрутизацию между этими контейнерами на уровне ОС.

**ipvlan:** Сети ipvlan предоставляют пользователям полный контроль над адресацией IPv4 и IPv6. Драйвер VLAN построен на основе этой возможности, предоставляя операторам полный контроль над тегированием VLAN уровня 2 и даже маршрутизацией IPvlan L3 для пользователей.

### CRI, CSI, CNI — что это?

**CRI** ( container runtime interface ) - это интерфейс который отвечает за жизенный цикл контейнера и среду выполнения этого контейнера ( docker, containered и тд. )

**CSI** ( container storage interface ) - это интерфейс который позволяет, как я понял, стандартизировать подключения каких то хранилищ к контейнеру

**CNI** ( container network interface ) - это интерфейс, который позволяет тюнить сетевые взаимодействия как между контейнерами ( создает сетевые окружения для пода + занимается маршрутизаций трафика между подами и нодами )

| Термин | Описание                                                                                                                                              | Область применения                         | Уровень взаимодействия                                  | Примеры реализации        |
|--------|-------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------|---------------------------------------------------------|---------------------------|
| **CRI** | Интерфейс для управления жизненным циклом контейнеров в Kubernetes. Позволяет Kubernetes взаимодействовать с различными средами выполнения контейнеров. | Оркестрация и управление контейнерами       | Инфраструктурный уровень, взаимодействие с контейнерами  | Docker, containerd, CRI-O |
| **CSI** | Стандарт для подключения систем хранения данных к контейнерам. Позволяет интегрировать разные решения для управления данными в контейнерах.             | Хранение и доступ к данным в контейнерах    | Инфраструктурный уровень, взаимодействие с системами хранения | OpenEBS, Rook, Portworx   |
| **CNI** | Спецификация для настройки сетевых интерфейсов контейнеров. Управляет сетевыми настройками и политиками безопасности для контейнеров.                   | Управление сетями и коммуникацией контейнеров | Интерфейс для сетевых плагинов на уровне контейнеров     | Calico, Flannel, Weave Net |
