---
title: Need Sort
description: На сортировку
icon: ArrowDownUp
---

## Железячные вопросы

### Сервер не отвечает, как можно получить доступ к серверу, не находясь непосредственно в ЦОДЕ

- Ответ

Через IPMI или kvm если оно есть на сервере.
Ну или звонить дежурному инженера ЦОДА, если иных опций нет.

---

### Что такое kvm(не гипервизор)? Как можно его использовать?

- Ответ
  KVM (или kvm over ip) — устройство, позволяющее передавать видеосигнал и ввод с мыши/клавиатуры по сети с использованием IP-протокола от вашего сервера. При помощи KVM вы можете перезагрузить сервер, получить доступ в BIOS сервера и к другим функциям, которые невозможно выполнить на сервере через терминал. То есть он обособлен от операционной системы.
  Часто используется как последнее средств. Когда сервер не грузится, или есть ещё какой-то программный или системный сбой.
  KVM - это аббревиатура, состоящая из слов. Клавиатура, монитор(видео), мышь.

---

### Что такое IPMI? Какие подсистемы он в себя включает?

- Ответ
  IPMI (Intelligent Platform Management Interface) – это интерфейс для удаленного мониторинга и управления физическим состоянием сервера.
  Как я понимаю, модуль находится внутри самого сервера. И называется он BMC. Контроллер управления.
  В случае утраты контроля над работой сервера, можно удаленно управлять его работой, а именно:

  - получить доступ к консоли, изменить настройки BIOS;

  - перезагрузить, включить/выключить сервер;

  - ознакомиться с состоянием сервера (слежение за температурными
    датчиками, датчиками напряжения, состояние блока питания, скорость
    вращения вентиляторов);

  - подключение образов .iso.
    Но вообще, BMC ― это отдельный компьютер со своим программным обеспечением и сетевым интерфейсом, который распаивают на материнской плате или подключают как плату расширения по шине PCI management bus.
    К BMC контроллеры подключаются через интерфейс IPMB (Intelligent
    Platform Management Bus ― шина интеллектуального управления платформой).
    IPMB ― это шина на основе I2C (Inter-Integrated Circuit), по которой
    BMC перенаправляет команды управления к различным частям архитектуры:
  - Общается с дополнительными контроллерами (MCs)
  - Считывает данные сенсоров (Sensors)
  - Обращается к энергонезависимому хранилищу (Non-Volatile Storage)
    Архитектура IPMI реализована так, что удаленный администратор не
    имеет прямого доступа к компонентам системы. Например, чтобы получить
    данные с сенсоров, удаленный администратор посылает команду на BMC, а
    BMC в свою очередь обращается к сенсорам.
    Подробнее о технологии можно почитать по ссылке:  
     [https://selectel.ru/blog/ipmi-obzor-texnologii/](https://selectel.ru/blog/ipmi-obzor-texnologii/)

---

### Какие преимущества предоставляет IPMI в сравнении с kvm?

- Ответ
  Недостатки модуля IP-KVM в сравнении с IPMI
  Традиционные внешние IP-KVM устройства позволяют вам удаленно работать
  только с консолью своего сервера, отсутствует возможность управления
  питанием, монтирования образов и контроля состояния датчиков сервера.
  У IP-KVM есть несколько ключевых недостатков:
  - отсутствие постоянного доступа к управлению сервером (чтобы
    воспользоваться IP-KVM, вам нужно создать запрос в техподдержку с
    просьбой подключить к вашему серверу временный IP-KVM в датацентре;
    заявку желательно подавать заранее, подключение занимает от 15 до 30
    минут в лучшем случае; в подключении KVM может быть отказано, если
    сейчас в наличии нет свободного оборудования);
  - отсутствие возможности управлять питанием, монтировать образы и контролировать состояние датчиков сервера.

---

## Просмотр информации о железной составляющей сервера

### Модели процессора, количестве физических и логических ядер, поддерживаемых инструкциях, режиме работы?

- Ответ

  - Модель процессора `cat /proc/cpuinfo`

  ```
  model name	: Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz
  model		: 45
  ```

  Та же модель процессора через `lscpu`

  ```
  Model name:          Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz
  ```

  Ядра физические и логические

  ```
  vm13 : ~ [0] # grep "cpu cores" /proc/cpuinfo |sort -u |cut -d":" -f2
   4
  vm13 : ~ [0] # grep -c "processor" /proc/cpuinfo
  4
  ```

  Поддерживаемые инструкции /proc/cpuinfo и lscpu

  Но возможно стоит также в спецификацию посмотреть

  ```
  Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology pni pclmulqdq vmx ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm kaiser tpr_shadow vnmi flexpriority ept vpid tsc_adjust xsaveopt arat
  ```

  режимы работы процессора

  `find / -name scaling_governor`

  `find / -name scaling_max_freq`

  `cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor`

  - **powersave** — режим энергосбережения, ядро будет работать на пониженных частотах
  - **ondemand** — режим зависящей от текущей нагрузки на ядро
  - **performance** — режим максимальной мощности, выставляет максимально возможную частоту

  - Физические ядра - это число физических ядер, реальных аппаратных компонентов.

  Логические ядра - это число физических ядер, умноженное на количество потоков, которые могут выполняться на каждом ядре с помощью гиперпотока.
  например, мой 4-ядерный процессор запускает два потока на ядро, поэтому у меня есть 8 логических процессоров.

  Узнать сколько ядер доступно можно командой:

  ```
  dmidecode -t processor | grep "Core Enabled:"
  Core Enabled: 6
  Core Enabled: 6
  ```

  Видим, что на данной системе находится 12 физических ядер (6+6). Соответственно, нормальный показатель LA должен быть менее 12. Однако, на процессорах Intel используется технология [Hyper-Threading](http://www.intel.ru/content/www/ru/ru/architecture-and-technology/hyper-threading/hyper-threading-technology.html), которая делит одно физическое ядро на два логических.

  ```
  dmidecode -t processor | grep "Thread Count:"
  Thread Count: 12
  Thread Count: 12
  ```

  Соответственно, в данном случае в системе может быть одновременно 24 виртуальных процессора (потока).

  Технология Turbo Boost позволяет процессору «разгоняться» и работать на частоте выше заявленной (т.е. выше 100%, выше единицы). Какой показатель LA считать нормальным в данном случае является предметом споров.

  ***

### Типы оперативной памяти, модели материнской платы, версии BIOS?

    **Оперативная память**

    ```
    dmidecode --type memory
    # dmidecode --type 17
    # dmidecode 2.11
    SMBIOS 2.8 present.

    Handle 0x1100, DMI type 17, 40 bytes
    Memory Device
    	Array Handle: 0x1000
    	Error Information Handle: Not Provided
    	Total Width: Unknown
    	Data Width: Unknown
    	Size: 9216 MB
    	Form Factor: DIMM
    	Set: None
    	Locator: DIMM 0
    	Bank Locator: Not Specified
    	Type: RAM
    	Type Detail: Other
    	Speed: Unknown
    	Manufacturer: QEMU
    	Serial Number: Not Specified
    	Asset Tag: Not Specified
    	Part Number: Not Specified
    	Rank: Unknown
    	Configured Clock Speed: Unknown

    Handle 0x004F, DMI type 17, 34 bytes
    Memory Device
    	Array Handle: 0x003F
    	Error Information Handle: Not Provided
    	Total Width: 72 bits
    	Data Width: 64 bits
    	Size: 16384 MB
    	Form Factor: DIMM
    	Set: None
    	Locator: P2_DIMMH2
    	Bank Locator: Node1_Bank0
    	Type: DDR3
    	Type Detail: Registered (Buffered)
    	Speed: 1333 MHz
    	Manufacturer: Samsung
    	Serial Number: 85D3A920
    	Asset Tag: Dimm10_AssetTag
    	Part Number: M393B2G70BH0-Y
    	Rank: 2
    	Configured Clock Speed: 1333 MHz
    ```

    Материнская плата

    ```

    dmidecode --type baseboard
    Handle 0x0002, DMI type 2, 15 bytes
    Base Board Information
    	Manufacturer: Supermicro
    	Product Name: X9DR3-F
    	Version: 0123456789
    	Serial Number: VM16BS021748
    	Asset Tag: To be filled by O.E.M.
    	Features:
    		Board is a hosting board
    		Board is replaceable
    	Location In Chassis: To be filled by O.E.M.
    	Chassis Handle: 0x0003
    	Type: Motherboard
    	Contained Object Handles: 0
    ```

    Версия bios

    ```bash
    storage8 : ~ [130] # dmidecode --type BIOS
    # dmidecode 2.11
    SMBIOS 2.7 present.

    Handle 0x0000, DMI type 0, 24 bytes
    BIOS Information
    	Vendor: American Megatrends Inc.
    	Version: 3.2a
    ```

---

### Текущих значениях датчиков напряжения, температуры, оборотов вентиляторов?

- Ответ, нужно дополнить
  Температура и всякие такие штуки можно смотреть в `sensors`

  ```bash
  sorsstorage13 : ~ [0] # sensors
  coretemp-isa-0001
  Adapter: ISA adapter
  Core 0:       +32.0°C  (high = +85.0°C, crit = +95.0°C)
  Core 1:       +36.0°C  (high = +85.0°C, crit = +95.0°C)
  Core 9:       +27.0°C  (high = +85.0°C, crit = +95.0°C)
  Core 10:      +39.0°C  (high = +85.0°C, crit = +95.0°C)

  intel5500-pci-00a3
  Adapter: PCI adapter
  temp1:        +65.5°C  (high = +100.0°C, hyst = +95.0°C)
                         (crit = +110.0°C)

  coretemp-isa-0000
  Adapter: ISA adapter
  Core 0:       +39.0°C  (high = +85.0°C, crit = +95.0°C)
  Core 1:       +38.0°C  (high = +85.0°C, crit = +95.0°C)
  Core 9:       +31.0°C  (high = +85.0°C, crit = +95.0°C)
  Core 10:      +29.0°C  (high = +85.0°C, crit = +95.0°C)
  ```

  Но большая часть информации через ipmicfg может взяться

  ```bash
  sorshocking : ~ [0] # ipmicfg -pminfo
   [SlaveAddress = 78h] [Module 1]
   Item                           |                          Value
   ----                           |                          -----
   Status                         |              [STATUS OK] (00h)
   Input Voltage                  |                        227.2 V
   Input Current                  |                         0.52 A
   Main Output Voltage            |                        12.09 V
   Main Output Current            |                         9.37 A
   Temperature 1                  |                        33C/91F
   Temperature 2                  |                       41C/106F
   Fan 1                          |                       3968 RPM
   Fan 2                          |                          0 RPM
   Main Output Power              |                          113 W
   Input Power                    |                          126 W
   PMBus Revision                 |                           0x22
   PWS Serial Number              |                P7061VF28GT1194
   PWS Module Number              |                    PWS-706P-1R
   PWS Revision                   |                            1.1
   Current Sharing Control        |           Active - Active (80)

   [SlaveAddress = 7Ah] [Module 2]
   Item                           |                          Value
   ----                           |                          -----
   Status                         |              [STATUS OK] (00h)
   Input Voltage                  |                        226.5 V
   Input Current                  |                         0.59 A
   Main Output Voltage            |                        12.09 V
   Main Output Current            |                        10.50 A
   Temperature 1                  |                        35C/95F
   Temperature 2                  |                       41C/106F
   Fan 1                          |                       4384 RPM
   Fan 2                          |                          0 RPM
   Main Output Power              |                          127 W
   Input Power                    |                          147 W
   PMBus Revision                 |                           0x22
   PWS Serial Number              |                P7061VF28GT1193
   PWS Module Number              |                    PWS-706P-1R
   PWS Revision                   |                            1.1
   Current Sharing Control        |           Active - Active (80)
  ```

---

### Типе используемого сетевого адаптера и состоянии его интерфейсов?

- Ответ
  ```bash
  sorsstorage13 : ~ [0] # lspci | grep net
  01:00.0 Ethernet controller: Intel Corporation 82576 Gigabit Network Connection (rev 01)
  01:00.1 Ethernet controller: Intel Corporation 82576 Gigabit Network Connection (rev 01)
  ```
  ```bash
  vm13 : ~ [0] # lshw -class network -short
  H/W path      Device       Class      Description
  =================================================
  /0/100/12     eth0         network    Virtio network device
  /0/100/13     eth1         network    Virtio network device
  /1            vethd2a5488  network    Ethernet interface
  /2            vethd29a7c3  network    Ethernet interface
  /3            veth12f3f63  network    Ethernet interface
  /4            veth39864d5  network    Ethernet interface
  /5            vethbe4b44c  network    Ethernet interface
  /6            veth62b367d  network    Ethernet interface
  /7            veth26cd9d1  network    Ethernet interface
  /8            veth2ab7aa7  network    Ethernet interface
  /9            vethb7e97f1  network    Ethernet interface
  ```
  ```bash
  vm13 : ~ [255] # ip a s eth0
  2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
      link/ether 3e:8e:90:47:59:70 brd ff:ff:ff:ff:ff:ff
      inet 5.101.156.76/24 brd 5.101.156.255 scope global eth0
  ```
  Или так
  ```bash
  vm13 : ~ [0] # ip link show
  1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1
      link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
  2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000
      link/ether 3e:8e:90:47:59:70 brd ff:ff:ff:ff:ff:ff
  3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000
      link/ether 2e:84:f2:32:05:88 brd ff:ff:ff:ff:ff:ff
  ```
  Здесь можно увидеть понятие up, означает что интерфейс поднят
  - UP — устройство подключено и готово принимать и отправлять фреймы;
  - LOOPBACK — интерфейс является локальным и не может взаимодействовать с другими узлами в сети;
  - BROADCAST - устройство способно отправлять широковещательные фреймы;
  - POINTTOPOINT — соединение типа «точка-точка»
  - PROMISC — устройство находится в режиме «прослушивания» и принимает все фреймы.
  - NOARP — отключена поддержка разрешения имен сетевого уровня.
  - ALLMULTI — устройство принимает все групповые пакеты.
  - NO-CARRIER — нет связи (не подключен кабель).
  - DOWN — устройство отключено.
    Еще можно вот так посмотреть:
  ```bash
  ls /sys/class/net
  additional-docker-sys-sys    docker0  eth1  veth12f3f63  veth2ab7aa7  veth62b367d  vethbe4b44c  vethd2a5488
  br-a67eedd3a789  eth0     lo    veth26cd9d1  veth39864d5  vethb7e97f1  vethd29a7c3
  ```

---

### Подключённых USB и PCI устройствах?

- Ответ
  PC
  ```bash
  lspci -vvv
  ```
  USB
  ```bash
  lsusb -vvv
  ```

---

## Linux

### Расскажи, как происходит процесс загрузки ОС linux с момента нажатия кнопки питания.

- Процесс загрузки системы

  Этапы следующие

  img https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled.png

  1. При включении компьютера цп переходит на адрес биоса и загружает биос.
  2. Биос, или uefi проходит кучу проверок и согласно своим проверкам носитель информации.
  3. На носителе находится MBR или GPT где находится загрузчик. Дальше по обстоятельствам. Загрузчик может загружать ось, а может передать управление дальше.
     Например, если у нас есть несколько систем на нескольких разделах.  
     Под первой частью загрузки подразумевается небольшая часть машинного кода, которая запускает второй загрузчик. Потому что выделяется 446 байт. Там ничего не поместится.
  4. Итого загрузчик первого этапа загружает загрузчик второго и кладет данные в оперативку.
     Загрузчик, зная где лежит загрузчик ос, грузит его, и грузит initial ram disk - там лежат модули ядра. Они также являются драйверами, которые необходимы для загрузки всей остальной системы.

  5. Затем ядро берет всё на себя. Инициализация устройств, конфигурирование процессора, памяти
  6. Далее запускается пользовательская среда, процесс init

  **супер коротко**

  1. загрузка биоса либо UEFI.
  2. биос либо UEFI проверяет работоспособность всех компонентов и запускает бутлоадер,
     ищет его в MBR или GPT разделе на диске.
  3. бутлоадер грузит OS.
  4. она уже грузит ядро.
  5. ядро конфигурирует уже всю память, процессор и тд.
  6. ядро запускает init процесс.
  7. запускаются все сервисы.
  8. логин в систему.
  9. запускаются скрипты оболочки юзера аля .bashrc, .zshrc, zprofile и тд.

  Полная подробная по загрузке пк вы можете увидеть по ссылке:
  [https://vc.ru/dev/137548-pusk-v-detalyah-kak-zagruzhaetsya-server](https://vc.ru/dev/137548-pusk-v-detalyah-kak-zagruzhaetsya-server)

---

### Что за процессы в Linux c PID 0 и 1

- Ответ
  Процесс с PID 0 - это процесс swap (или идл процесс).
  Этот процесс не выполняет никаких задач, он является бездействующим.
  Процессор переходит к выполнению процесса 0, когда нет других активных процессов для выполнения.
  Процесс с PID 1 - это init процесс (или systemd в современных дистрибутивах Linux).
  Это первый процесс, который запускается во время загрузки системы после ядра Linux.
  Он является родительским процессом для всех остальных процессов в системе.
  init процесс отвечает за запуск различных системных служб и демонов при загрузке.
  Если init процесс завершается, это приводит к остановке всей системы.

---

### Что такое POSIX

- Ответ

  ### Интерфейс портативных операционных систем (POSIX)

  **Портативность** в контексте стандарта POSIX относится к исходному коду, а не к бинарным файлам, которые собираются из этого исходного кода. Это означает, что программы, написанные с соблюдением стандартов POSIX, могут быть скомпилированы и запущены на различных операционных системах без значительных изменений в исходном коде.

  **Интерфейс** — это способ взаимодействия вашего кода с остальной системой. POSIX определяет общий интерфейс, который описывает, как программы должны взаимодействовать с операционной системой.

  Таким образом, программы, разработанные для одной операционной системы, могут быть легко перенесены на другую, если обе системы поддерживают стандарт POSIX.

  Некоторые из ключевых аспектов POSIX включают:

  - **Семафоры** — механизм для синхронизации процессов и разделения ресурсов.
  - **Управление потоками** — стандарты для работы с потоками, синхронизации и управления ими.

  POSIX предоставляет основу для того, чтобы разработчики могли писать программы, которые будут совместимы с различными операционными системами, обеспечивая высокую степень переносимости кода.

---

### Что такое уровни выполнения (run levels) в Linux

- Ответ

  В Linux существует понятие **уровень выполнения** (_run level_), который обозначается числами от 0 до 6. Каждый уровень выполнения соответствует определённому состоянию системы.

  Система в любой момент времени находится на определённом уровне выполнения. Как системный администратор, вы можете переводить её с одного уровня выполнения на другой с помощью программы `init` (или `telinit`), передавая в качестве аргумента число, соответствующее нужному уровню выполнения.

  ### Описание уровней выполнения

  - **0** — система выполняет действия по выключению.
  - **1** — **однопользовательский режим** (_single user mode_). Предназначен для административных задач, например, восстановления системы. По функциональности напоминает безопасный режим (_Safe Mode_) в Windows, однако не является его полной аналогией. В этом режиме система сконфигурирована, но не запущен ни один сервис, и может работать только один пользователь — `root`.
  - **2** — **многопользовательский режим без сетевых файловых систем**. Не используется во многих дистрибутивах, но в Debian используется как стандартный многопользовательский режим.
  - **3** — **многопользовательский режим с сетевыми возможностями**. Это нормальный режим работы сервера без графического интерфейса.
  - **4** — **не используется** в большинстве систем. В Slackware Linux используется для графического входа в систему.
  - **5** — **графический режим**. В RedHat и SuSE Linux этот уровень используется для графического входа в систему. В Slackware не сконфигурирован.
  - **6** — выполняются действия по перезагрузке системы.

  ### Примечания к уровням выполнения

  - В большинстве современных систем уровни выполнения заменены на **systemd targets**, но принцип остаётся аналогичным.

---

### Какие основные части компоненты включает в себя система на базе дистрибутива linux?

- Написать ответ

  1. **Начальный загрузчик (GRUB)**  
     GRUB (Grand Unified Bootloader) — это программа, которая отвечает за загрузку операционной системы. Она выполняется на этапе начальной загрузки и предоставляет выбор операционных систем или конфигураций для загрузки ядра.

  2. **Ядро Linux**  
     Ядро — это центральная часть операционной системы. Оно управляет ресурсами компьютера, такими как процессор, память и устройства ввода-вывода. Ядро выполняет важнейшие функции, включая управление процессами, памятью и взаимодействие с аппаратным обеспечением.

  3. **Демоны**  
     Демоны — это фоновые процессы, которые работают в системе и выполняют различные задачи без вмешательства пользователя. Примеры: `cron` (планировщик задач), `sshd` (управление удалёнными соединениями).

  4. **Командная оболочка (Shell)**  
     Оболочка — это интерфейс между пользователем и операционной системой. Она позволяет вводить команды и запускать программы. Примеры командных оболочек: `bash`, `zsh`, `fish`.

  5. **Утилиты командной оболочки**  
     Это набор команд и программ, которые выполняются из командной строки. Примеры таких утилит: `ls` (список файлов), `cp` (копирование файлов), `grep` (поиск текста).

  6. **Графический сервер**  
     Графический сервер, такой как [X.org](http://x.org), управляет графическим интерфейсом, видеокартой, монитором, мышью и другими устройствами ввода-вывода, необходимыми для отображения и взаимодействия с пользователем.

  7. **Среда рабочего стола**  
     Среда рабочего стола — это графический интерфейс, предоставляющий пользователю доступ к утилитам и инструментам операционной системы. Примеры: KDE, GNOME, Xfce, Cinnamon. Они включают в себя различные программы, такие как файловые менеджеры, панель задач и другие утилиты.

  8. **Программы рабочего стола**  
     Программы рабочего стола — это приложения, которые запускаются в рамках среды рабочего стола, такие как текстовые редакторы, браузеры, почтовые клиенты и файловые менеджеры, специфичные для каждой среды.

---

### Что такое BIOS, UEFI? Основы и различия

- Ответ

  #### BIOS (Basic Input-Output System)

  **BIOS** — это низкоуровневое программное обеспечение, которое хранится на микросхеме, расположенной на материнской плате компьютера. Оно загружается при включении ПК и отвечает за инициализацию аппаратных компонентов, обеспечивая их правильную работу, а затем запускает загрузчик операционной системы.

  Когда компьютер включается, **BIOS** выполняет самотестирование — **POST (Power-On Self Test)**. В процессе тестирования проверяется конфигурация и работоспособность оборудования. Если обнаружены ошибки, BIOS может издавать звуковые сигналы (пищать) или выводить коды ошибок. После этого BIOS ищет загрузочную запись или MBR (Master Boot Record) и запускает загрузчик системы.

  BIOS также взаимодействует с **CMOS** (Дополнительный металл-оксид-полупроводник), небольшой памятью с батарейным питанием, где хранятся настройки BIOS, такие как конфигурация оборудования, системное время и параметры загрузки.

  #### Ограничения BIOS:

  - BIOS поддерживает загрузку только с дисков объемом до **2.1 ТБ**, так как использует **MBR** для разметки дисков.
  - BIOS работает в режиме **16-разрядного процессора** и имеет всего **1 МБ свободной памяти**.
  - У BIOS есть проблемы с одновременной инициализацией нескольких аппаратных устройств.

  Из-за этих ограничений BIOS считается устаревшей технологией.

  #### UEFI (Unified Extensible Firmware Interface)

  В 2007 году был разработан новый стандарт — **UEFI**, который заменяет BIOS и устраняет его ограничения. UEFI — это современная прошивка, которая предоставляет более гибкие возможности для взаимодействия с аппаратным обеспечением и операционной системой.

  #### Преимущества UEFI по сравнению с BIOS:

  - Поддержка загрузки с дисков объемом до **2.2 ТБ** и выше (до **9.4 зетабайт**) с использованием **GPT** (GUID Partition Table).
  - Работает в **32-битном** или **64-битном** режиме, что позволяет иметь большее адресное пространство и более быстрый запуск системы.
  - В UEFI есть поддержка графики и мыши, что делает интерфейс более удобным, хотя это не обязательно.
  - **Безопасная загрузка (Secure Boot)** — UEFI проверяет целостность загружаемых компонентов, что защищает от загрузки неподписанного или изменённого программного обеспечения.
  - Поддержка сетевых функций в прошивке, что позволяет загружаться через сеть (PXE).

  UEFI можно рассматривать как маленькую операционную систему, которая работает поверх прошивки ПК. Она может храниться на флеш-памяти и обладает значительно большими возможностями по сравнению с BIOS.

  #### Заключение

  BIOS был основным методом управления запуском системы на протяжении десятилетий, но его ограничения привели к созданию UEFI, более мощного и гибкого стандарта, который поддерживает современные технологии и устраняет недостатки BIOS.

---

### Что такое PXE? Как загрузиться по сети?

- Ответ

  **PXE** (читается как "пикси") — это среда, которая позволяет компьютеру загружаться по сети с помощью сетевой карты. Это особенно удобно для установки операционных систем без необходимости постоянно использовать физические носители, такие как флешки или диски.

  #### Как работает PXE:

  1. При включении компьютера, последовательность запуска выглядит так:

     - Подача питания → **BIOS** → инициализация сетевой карты через её собственный стек (ЗЧУ).
     - После этого запускается программа сетевой загрузки **NBP** (Network Boot Program), которая загружается с **TFTP-сервера** (Trivial File Transfer Protocol) в оперативную память компьютера.
     - Далее загружается образ операционной системы или установочный образ.

  2. **PXE-код** встроен в ПЗУ сетевой карты. Он отвечает за получение исполняемого файла по сети, используя протокол **TFTP**.

  #### Преимущества PXE:

  PXE позволяет системным администраторам устанавливать операционные системы на компьютеры удалённо, без необходимости использовать физические носители. Это особенно полезно для массовой установки систем в корпоративных сетях.

  #### Настройка PXE-загрузки:

  1. Зайдите в **BIOS** или **UEFI**.
  2. Найдите раздел **Advanced** или похожий, в зависимости от версии BIOS.
  3. Найдите опцию, связанную с загрузкой по сети, такую как **LAN Boot** или **Network Boot**, и включите её.

  #### Примечание:

  - При включённой функции **Fast Boot** сетевые карты могут загружаться через агент сетевой загрузки, например, **Network Atheros Boot Agent**.

  Таким образом, PXE позволяет загружать операционные системы напрямую по сети, что упрощает массовую установку и обслуживание системы.

---

### Что такое ядро, initramfs, загрузчик?

- Ответ
  **Ядро** - это самый низкий уровень программного обеспечения, которое взаимодействует с аппаратными средствами компьютера. Оно отвечает за взаимодействие всех приложений, работающих в пространстве пользователя вплоть до физического оборудования.
  **Initramfs** - основная цель предоставить пользователю его файлы, которые размещены в файловой системе. То есть для ядра нужно найти, примонтировать файловую систему и предоставить пользователю.
  **Загрузчик** операционной системы — системное программное обеспечение, обеспечивающее загрузку операционной системы непосредственно после включения компьютера (процедуры POST) и начальной загрузки.

---

### Зачем нужна система инициализации? Какие системы инициализации используются в современных дистрибутивах? (2 - 5 штук) (init)

- Ответ
  В операционной системе Linux и других системах семейства Unix после завершения загрузки ядра начинается инициализация Linux системы, сервисов и других компонентов. За это отвечает процесс инициализации, он запускается ядром сразу после завершения загрузки, имеет PID 1, и будет выполняться пока будет работать система.
  За время развития операционных систем были созданы различные системы инициализации Linux. В разных дистрибутивах использовались разные системы
  Есть init. Это первый процесс, родительский процесс, которые все процессы запускает. Проверка, монитрование файловых систем, запуск служб.
  Есть три его варианты работы
  **System V init (SysV)**
  Это загрузка, основанная на уровне запуска. Обычно их семь. Ну там включение, выключение, режим восстановления и тп.
  То есть процесс инициализирует на одном из уровней запуска системы
  **SystemD**
  Родительский процесс, который запускает инициализацию в ускоренном режиме за счет параллельного запуска задач. Ускоренный режим достигается за счет особенностей работы процессора. И если они позволяют, запускает инициализацию параллельно.
  **Upstart**
  Здесь запускаются скрипты инициализации, отслеживает события, и реагирует на них. Более гибкий процесс инициализации. Если какая-то служба не запустилась, или вдруг упала, то апстарт это отследит и запустит повторно.

---

### Что такое systemd и init ? В чем основное преимущество первого над вторым ?

- Ответ
  И то, и то система инциализации.
  В чём конкретно преимущества для меня systemd над init:
  - Параллельный старт процессов, в отличие от init
  - Запуск системы с ним быстрее происходит.
  - Не нужно городить костыли на баше — использую простенький
    шаблон для юнитов, в отличие от баш портянки.
  - Не нужно городить километровые пайпы для чтения нужной информации из логов — для всего есть человекопонятные опции;
  - Автоматический рестарт юнитов при падении — не нужно плясать с бубном вокруг ряда сервисов, если выпал один промежуточный;
  - Простая и понятная настройка всего — несколько конфигов (а не тонны, раскиданные по всей системе, как было в легаси) с парами
    ключ=значение;
  - Хорошая документированность (я не говорю, что легаси-набор плохо документирован, я лишь говорю, что systemd не уступает);
  - Он не только загрузчик, но и система инициализирующая демоны

---

### Как понять используется ли в системе systemd?

- Ответ

  `/run/systemd/` говорит о наличии systemd в системе.

  `/run/systemd/system/` - говорит о том, что это активная система инициализации

  Можно через stat узнать

  Если есть симлинк - используется systemd.

  ```
  stat /sbin/init
  File: ‘/sbin/init’ -> ‘../lib/systemd/systemd’
  ```

  Можно сделать ещё через процесс 1, и через файловую систему `/proc`:

  ```
  root@swfuse:~# stat /proc/1/exe
  File: /proc/1/exe -> /lib/systemd/systemd
  Size: 0         	Blocks: 0          IO Block: 1024   symbolic link
  Device: 4h/4d	Inode: 444358      Links: 1
  Access: (0777/lrwxrwxrwx)  Uid: (    0/    root)   Gid: (    0/    root)
  Access: 2022-06-20 00:00:01.579875809 +0000
  Modify: 2022-06-09 17:19:41.581240179 +0000
  Change: 2022-06-09 17:19:41.581240179 +0000
  ```

---

### Опишите, что происходит (с точки зрения процессов), при выполнении любой команды в консоли, например:

`$ ls -l`

- **Ответ**
  При выполнении команды в консоли происходит системный вызов fork(), в результате которого создаётся копия процесса консоли, затем копия процесса выполняет команду с помощью системного вызова exec().
  После выполнения команды, копия процесса выполняет системный вызов exit(), в результате которого оригинальному процессу консоли отправляется сигнал SIGCHLD (сообщающий о том, что дочерний процесс завершён).
  Во время работы копии процесса, оригинальный процесс находится в ожидании из-за системного вызова wait().

---

**Как работает система разграничения доступа к
файлам в linux? Какие возможности она предоставляет?**

- Ответ
  [https://webistore.ru/administrirovaniye-unix/prava-dostupa-k-fajlam-i-direktoriyam-v-linux-chast-1/](https://webistore.ru/administrirovaniye-unix/prava-dostupa-k-fajlam-i-direktoriyam-v-linux-chast-1/)
  [https://webistore.ru/administrirovaniye-unix/prava-dostupa-k-fajlam-i-direktoriyam-v-linux-chast-2/](https://webistore.ru/administrirovaniye-unix/prava-dostupa-k-fajlam-i-direktoriyam-v-linux-chast-2/)
  [https://webistore.ru/administrirovaniye-unix/prava-dostupa-k-fajlam-i-direktoriyam-v-linux-chast-3/](https://webistore.ru/administrirovaniye-unix/prava-dostupa-k-fajlam-i-direktoriyam-v-linux-chast-3/)
  - Оболочка проверяет, являетесь ли вы владельцем файла, к которому вы хотите получить доступ. Если вы являетесь этим владельцем, вы получаете разрешения и оболочка прекращает проверку.
  - Если вы не являетесь владельцем файла, оболочка проверит, являетесь ли вы участником группы, у которой есть разрешения на этот файл. Если вы являетесь участником этой группы, вы получаете доступ к файлу с разрешениями, которые для группы установлены, и оболочка прекратит проверку.
  - Если вы не являетесь ни пользователем, ни владельцем группы, вы получаете права других пользователей (Other).

---

### Как посмотреть нагрузку на диски?

- Ответ
  Установить утилиту `sysstat`, проверить нагрузку на диски `iostat -xtc`.  
   Использовать утилиту `iotop`, которая показывает процессы, которые активно используют диск.  
   Использовать `dstat` - утилита, которая выводит раз в какое-то время статистику по системным ресурсам. В целом более удобная замена таких утилит как vmstat, iostat, ifstat

---

### В чем разница между объявлением переменной `export VAR="VALUE"` и `VAR="VALUE"` в bash?

- Ответ
  При объявлении переменной через **export** - переменная будет доступна в любых других процессах.
  При обычном объявлении переменной - переменная будет доступна только в запущенном процессе.

---

### Что значит `$@`, `$!`, `$?`, `$$` в bash?

- Ответ
  `$@` - показывает все параметры переданные скрипту.  
   `$!` - показывает pid последнего процесса, которая оболочка запустила в фоновом режиме.  
   `$$` - показывает текущий pid процесса.  
   `$?` - показывает с каким кодом завершилась последняя выполненная функция. 0 - успешное выполнение.

---

### Как выполнить фильтрацию вывода команды, чтобы на экран были выведены только ошибки (STDERR), игнорируя STDOUT?

- Ответ
  ```bash
  cmd 2>&1 >/dev/null | grep pattern
  ```

---

### При перенаправлении команд (command1 | command2 ) перенаправляется только stdout. Как сделать так, чтобы stderr тоже перенаправлялся?

- Ответ
  Либо использовать перенаправление. То есть перенаправляется второй файловый дескриптор туда, куда направлен stdout:  
   `command1 2>&1 | command2`

  Либо использовать более укороченную версию:  
   `command1 |& command2`

---

### Как посмотреть описание дескриптора? Как посмотреть время последней модификации файла?

- Ответ
  Посмотреть полную информацию по дескриптору возможно командой `stat <path_to_file>`.
  Время модификации командой `stat --format=%y dira`

---

### Как работает sudo? Для чего она используется?

- Ответ
  Sudo позволяет подменить пользователя и выполнить команду от его имени.
  Расшифровывается именно так - **s**ubstitute **u**ser and **do**
  По умолчанию выполнение команды происходит от имени суперпользователя.
  Например, вот эта команда
  ```bash
  sudo whoami
  ```
  И вот эта
  ```bash
  sudo -u swfuse whoami
  ```
  Будет отличаться результатом.
  Можно просмотреть какие полномочия есть с помощью команды:
  ```bash
  sudo -l
  ```

---

### Что такое userspace, kernelspace? Чем они отличаются?

- Ответ
  Под **пользовательским** пространством понимается весь код операционной системы, который находится вне ядра.
  Большинство Unix-подобных операционных систем (включая Linux) поставляются с разнообразными предустановленными утилитами, средствами разработки и графическими инструментами — это все приложения пространства пользователя.
  Все пользовательские приложения (и контейнеризированные и нет) при работе используют различные данные, но где эти данные хранятся?
  Какие-то данные поступают из регистров процессора и внешних устройств, но чаще они хранятся в памяти и на диске. Приложения получают доступ к данным, выполняя специальные запросы к ядру — системные вызовы. Например, такие как выделение памяти (для переменных) или открытие файла. В памяти и файлах часто хранится конфиденциальная информация, принадлежащая разным пользователям, поэтому доступ к ним должен запрашиваться у ядра с помощью системных вызовов.
  Ядро обеспечивает абстракцию для безопасности, оборудования и внутренних структур данных. Например, системный вызов open() используется для получения дескриптора файла в Python, C, Ruby и других языках программирования. Вряд ли бы вы хотели, чтобы ваша программа работала с XFS на уровне битов, поэтому ядро предоставляет системные вызовы и работает с драйверами. Фактически этот системный вызов настолько распространен, что является частью библиотеки POSIX .
  [https://habr.com/ru/company/otus/blog/565832/](https://habr.com/ru/company/otus/blog/565832/)
- Краткое определние
  - **Пользовательское пространство** представляющее собой набор местоположений, в которых выполняются обычные пользовательские процессы (т. е. все, кроме ядра). Роль ядра состоит в том, чтобы управлять приложениями, работающими в этом пространстве, от взаимодействия друг с другом и с машиной.
  - **Пространство ядра** , то есть место, где хранится и выполняется код ядра.
    Пользовательское пространство имеет доступ к ограниченной памяти, ядро имеет всю память.
    И чтобы работать приложения взаимодествуют через интерфейс, которое называется системным вызовом.

---

### Что такое системные вызовы? Зачем они нужны и как они работают? Какие системные вызовы знаешь (5-10)

- Ответ
  **Системный вызов** — это то, посредством чего код приложения, выполняющегося в пользовательском режиме, запрашивает службу, предоставляемую кодом, который выполняется в режиме ядра.
  **read** - чтение из файлового дескриптора.
  **open** - открывающий и по возможности создающий файл или устройство
  **close -** закрыть файловый дескриптор
  **access -** проверка пользовательских привелегий для этого файла
  **mmap** - служит для отображения предварительно открытого файла (например, с помощью системного вызоваа open()) в адресное пространство вычислительной системы
  Команда для вывода всех системных вызовов во время исполнения программы:

  ```bash
  strace -c ls
  % time     seconds  usecs/call     calls    errors syscall
  ------ ----------- ----------- --------- --------- ----------------
    0.00    0.000000           0         4           read
    0.00    0.000000           0         5           write
    0.00    0.000000           0         6           open
    0.00    0.000000           0         9           close
    0.00    0.000000           0         7           fstat
    0.00    0.000000           0        18           mmap
    0.00    0.000000           0        10           mprotect
    0.00    0.000000           0         2           munmap
    0.00    0.000000           0         3           brk
    0.00    0.000000           0         2           rt_sigaction
    0.00    0.000000           0         1           rt_sigprocmask
    0.00    0.000000           0         2           ioctl
    0.00    0.000000           0         6         6 access
    0.00    0.000000           0         1           execve
    0.00    0.000000           0         2           getdents
    0.00    0.000000           0         1           getrlimit
    0.00    0.000000           0         1           arch_prctl
    0.00    0.000000           0         1         1 futex
    0.00    0.000000           0         1           set_tid_address
    0.00    0.000000           0         1           openat
    0.00    0.000000           0         1           set_robust_list
  ------ ----------- ----------- --------- --------- ----------------
  100.00    0.000000                    84         7 total

  ```

---

### Где можно найти информацию о конкретном системном вызове?

- Ответ
  `man 2 <syscall>`
  Но нужно будет предварительно поставить пакет `man-pages`
  ```
  sudo apt install manpages-dev manpages-posix-dev
  ```

---

### Что делает команда kill?

- Ответ

  Назначение команды kill - отправить определенный сигнал процессу.
  По умолчанию используется сигнал SIGTERM.

  А вот все **сигналы** можно глянуть через kill -l, они нужны для взаимодействия между процессами

  ```
  root@swfuse:~# kill -l
   1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP
   6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR1
  11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM
  16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP
  21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ
  26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR
  31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3
  38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8
  43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13
  48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12
  53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7
  58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2
  63) SIGRTMAX-1  64) SIGRTMAX
  ```

---

### В чем разница между одинарными кавычками (') и двойными кавычками (")?

- Ответ  
   Одинарные кавычки ('):  
   Трактуют всё внутри них как текст. Если там есть переменные, то они раскрыты не будут
  Не позволяют подставить переменнные или выполнить команду.

  Двойные кавычки ("):  
   Позволяют подставлять переменные.  
   Позволяют подставить обратные кавычки для выполнения комманд

  Одинарная кавычка (переменная в выводе не подставляется, а выводится как текст):

  ```
  $ echo 'URL = https://$MYVAR.ru'
  URL = https://$MYVAR.ru
  ```

  Двойная кавычка (переменная в выводе подставляется как значение):

  ```
  $ echo "URL = https://$MYVAR.ru"
  URL = https://swfuse.ru
  ```

  Одинарная кавычка (выводит текст явно):

  ```
  echo 'Сегодняшняя дата: `date`'
  Сегодняшняя дата: `date`
  ```

  Двойная кавычка (внедряет результат выполнения команды в строку):

  ```
  $ echo "Сегодняшняя дата: `date`"
  Сегодняшняя дата: Wed Sep 18 10:59:45 RTZ 2024
  ```

---

### Приложение запущено как сервис - как посмотреть то, что оно написало в stdout?

- Ответ
  Либо попытаться найти логи юнита, если это что-то systemdшное. Как правило такие сервисы пишут логи.  
  `sudo journalctl -u [юнит, который нам нужен]`

  Либо попытаться найти в какой файл пишет процесс  
  `lsof -p PID | grep -E 'w|u'`

  Либо попытаться вывести его stdout через `strace`  
  `strace -e write -s 9999 -p 12345`  
  -e write - тут отслеживаем только системные вызовы write
  -s 9999 - показывать по 9999 символов в строке, чтобы точно всё влезло
  -p PID - интересующий нас идентификатор процесса.

  Но strace может замедлить работу процесса. И вывод нужно будет еще как-то интерпретировать, раскрыть.

  Например программа выводит в stdout следующее:

  ```
  Привет, это тестовое сообщение!
  Привет, это тестовое сообщение!
  ```

  А в strace это будет выглядеть вот так:

  ```
  write(1, "\320\237\321\200\320\270\320\262\320\265\321\202, \321\215\321\202\320\276 \321\202\320\265\321\201\321\202\320\276\320\262\320\276\320\265 \321\201\320\276\320\276\320\261\321\211\320\265\320\275\320\270\320\265!\n", 58) = 58
  write(1, "\320\237\321\200\320\270\320\262\320\265\321\202, \321\215\321\202\320\276 \321\202\320\265\321\201\321\202\320\276\320\262\320\276\320\265 \321\201\320\276\320\276\320\261\321\211\320\265\320\275\320\270\320\265!\n", 58) = 58
  ```

---

### Текущая load average на сервере - 900, 900, 900. Сервер работает с незначительной потерей производительности. Каким образом можно понять, является ли это нормальной ситуацией?

- Ответ

  Я бы начал с того, что бы понял а что вообще вызывает проблему, и что на сервере важное. Что работает, а что не работает.

  Если сайтики не открываются на работающем сервере все - проблема.
  Если проблема только с одним, то копать.
  А может быть все важные функции работают для работы сайтов или сервисов.

  И допустим нужно писать данные или читать данные на что-то медленное. Система не тормозит, но из-за того, что процессы записи чтения на медленный девайс скопились - ЛА подросла. В этом случае будет высокая wa
  При этом все остальные процессы отрабатывают быстро

  На параметр нагрузки LA влияет также и ожидание ввода-вывода (параметр _wa_
  в утилите _top_
  ) в дисков и задержка сети. Данные параметры могут не влиять на работу основных сервисов в системе, но учитываются при расчете общей нагрузки на систему.

  Иными словами на сервере с активными приложениями высокий LA скорее всего будет проблемной ситуацией.
  А на сервере с бэкапами высокий LA может проблемой не быть. Поскольку туда постоянно пишутся данные, и la растет просто из-за того, что копятся процессы, которые ожидают очереди записи на диск.

---

### Что такое процесс? Что такое тред? В чем заключаются их главные отличия?

- Ответ
  **Процесс** - это исполняемая программа. Когда программист пишет программу и выполняет ее, эта программа становится процессом. Он выполняет задачи в соответствии с инструкциями программы.
  **Процесс** - это экземпляр выполняемой компьютерной программы.
  **Поток** - это компонент процесса, который является самой маленькой исполнительной единицей.
  Можно представить процессы и потоки на примере задачи "Починка дороги".
  Хорошо, как я могу построить дорогу, поэтому мне нужен какой-то ресурс для строительства, верно?
  Выделяемые ресурсы:
  1. Граница дороги (область)
  - Технически мы можем назвать это виртуальным адресным пространством, оно имеет уникальный идентификатор процесса для идентификации работы.
  - Доступ к ограниченной границе области. Контекст безопасности
  - Также, вы можете сопоставить другие свойства процесса с приведенным выше примером (окружение, приоритет и т.д.)
  1. Жесткое или рабочее пространство
  - Количество "оборудования или рабочей силы" основано на мышлении подрядчика; предположим, что он хочет закончить работу быстро, тогда он должен назначить больше людей на эту работу.
  - Т.е. каждый работник может получить доступ к этой ограниченной территории (общее пограничное пространство).
  - Для начала работы нужен хотя бы один человек один поток.
  - У каждого человека есть свой идентификатор
    Ключевая разница
  - Процесс означает, что программа выполняется, а поток означает сегмент процесса.
  - Процесс не является легковесным, тогда как потоки - легковесными.
  - Процессу требуется больше времени для завершения, а потоку требуется меньше времени для завершения.
  - Процесс требует больше времени для создания, тогда как поток требует меньше времени на создание.
  - Процессу, требуется больше времени для переключения контекста, тогда как потокам требуется меньше времени для переключения контекста.
  - **Процесс в основном изолирован, тогда как потоки разделяют память.**
  - Процесс не обменивается данными, а потоки обмениваются данными друг с другом.

---

---

### Приложение пишет в логи too many opened files, как это диагностировать?

- Ответ  
  Сначала проверить лимиты для данного процесса:  
  `grep "Max open files" /proc/PID/limits`

  Также можно посмотреть лимиты для текущего пользователя:  
  `ulimit -n`

  Имеет смысл посмотреть лимиты systemd.  
  Что-то типа по пути: `/etc/systemd/system/<service_name>.service`  
  Можно найти такие строчки:

  ```
  [Service]
  LimitNOFILE=10
  ```

  Также можно заглянуть в лимиты по пути `/etc/security/limits.conf`, пример вывода:

  ```
  *           hard    nofile     65535
  *           soft    nofile      8192       # Required for certain games to run.
  ```

  Также пожно глянуть сколько вообще открыто файлов процессом.  
  `lsof -p PID`

  Через `strace` процесса можно глянуть какие процессы открываются, и, возможно, не закрываются.  
  `strace -e trace=open,close -p PID`

---

### Как заставить приложение перестать писать в файл, не завершая процесс?

- Ответ  
  Ищем нужный нам файловый дескриптор через `lsof -p $PID`  
  Например, это процесс с номером 1737, и файловым дескриптором 77.

  Вариант с gdb:

  ```
  gdb -p 1737
  ....
  (gdb) p close(77)
  $1 = 0
  ...
  ```

  Вариант с exec:  
  `exec 77>&-`

---

### Что такое CPU pinning

- Ответ

  Это механизм который прекреплять определенный процесс или поток к определенному ядру, что позволяет допустим прикреплять определенный конетйнер к определенному ядру, что убирает позволяет убрать тротлинг(механизм когда процессор при сильном перегреве понижает частоты).

---

### Какие алгоритмы планирования ресурсов в linux ты знаешь

- Ответ

  **Довольно редкий вопрос на самом деле**

  **CPU**:
  Completely Fair Scheduler (CFS) - когда в очередь ставятся процессы на основе их приоритета и времени исполнения
  Round Robin - когда на выполнения процессов выделяется определенное время для их выполнения процессором
  Shortest Job First(SJF) - когда процесс с наименьшем временем выполнения получает наивысший приоритет
  Multi-Level Feedback Queue (MLFQ)- когда динамически меняется приоритет процесса на основне его поведения.

  **Ввод/Вывод**:
  Completely Fair Queuing (CFQ) - Когда ставяться в очередь процессы на основе их приоритета, и пытается обеспечить равномерное распределение на все запросы.
  first come first serve (FCFS) - когда очеред операций обрабатывается в порядке поступления
  Deadline - когда алгоритм гарантирует, что запрос на диск будет обработан в заданный срок

  **Память**:
  Slab Allocation - когда кэшируются объекты одного типа вместе, что бы уменшить накладные ресурсы на выделение и освобождения памяти.

---

### Представлен вывод команды _top_. Что означает каждая запись в выводе?

```bash
top - 10:44:36 up 91 days, 19:29,  7 users,  load average: 0,00, 0,02, 0,05
Tasks: 156 total,   1 running, 155 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0,0 us,  1,5 sy,  0,0 ni, 96,9 id,  0,0 wa,  0,0 hi,  0,0 si,  1,5 st
KiB Mem : 12137392 total,  6227844 free,  1117728 used,  4791820 buff/cache
KiB Swap:        0 total,        0 free,        0 used. 10090148 avail Mem
```

- Ответ
  top - утилита
  10:44:36 — время системы
  up - сколько система работает с момента последнего запуска
  7 user - количество авторизованных юзеров в системе
  load average: 0.00, 0.02, 0.05 - параметр средней нагрузки на систему за период времени 1 минута, 5 минут, 15 минут
  156 total - всего процессов в системе
  1 running - количество процессов в работе
  155 sleeping - ожидание процесса или сигнала
  0 stopped - количество приостановленных процессов сигналом STOP или выполнение трассировки
  0 zombie - количество зомби-процессов, которые завершили своё выполнение, но присутствующие в системе, чтобы дать родительскому процессу считать свой код завершения.

| параметр                      | описание                                                                                                                                                                                                                                                 |
| ----------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| us (user)                     | Использование процессора пользовательским процессами                                                                                                                                                                                                     |
| sy (system)                   | Использование процессора системным процессами                                                                                                                                                                                                            |
| ni (nice)                     | Использование процессора процессами с измененным приоритетом с помощью команды nice                                                                                                                                                                      |
| id (idle)                     | Простой процессора. Можно сказать, что это свободные ресурсы                                                                                                                                                                                             |
| wa (IO-wait)                  | Время на простой, то есть ожидания переферийных устройств ввода вывода                                                                                                                                                                                   |
| hi (hardware interrupts)      | Показывает сколько процессорного времени было потрачено на обслуживание аппаратного прерывания. (Аппаратные прерывания генерируются аппаратными устройствами. Сетевыми картами, клавиуатурами, датчиками, когда им нужно о чем-то просигнализировать цп. |
| si (software interrupts)      | Показывает сколько процессорного времени было потрачено на обслуживание софтверного прерывания. Фрагмент кода, вызывающий процедуру прерывания                                                                                                           |
| st (stolen by the hypervisor) | Показывает сколько процессорного времени было «украдено» гипервизором. Для запуска виртуальной машины, или для иных нужд                                                                                                                                 |

    **KiB Mem** - количество оперативной памяти в кибибайтах (кратно 1024): *7106404 total* -- всего доступно оперативной памяти в системе, *306972 free* -- свободно оперативной памяти для использования, *3127144 used* -- использовано оперативной памяти, *3672288 buff/cache* -- буферизовано/закешировано оперативной памяти.

    **KiB Swap** - количество swap-памяти в кибибайтах (кратно 1024), которые выделено на диске: *8191996 total* - всего выделено swap-памяти, *8191996 free* - свободно swap-памяти *0 used* - использовано swap-памяти, *3270520 avail Mem* - доступно для использования swap-памяти.

---

### Что такое swap файл (подкачки)? Зачем он нужен, и как он работает? Какие данные в него записываются?

- Ответ

  Нужно начать с понятия подкачки, зачем она нужна.

  Зачем она нужна:

  1. Если системе требуется больше памяти, чем физически доступно, ядро выгружает менее используемые страницы и отдает память текущему приложению, процессу, которому память нужна немедленно.
  2. Значительное количество страниц могут использоваться только для инициализации. Система может выгрузить эти страницы и освободить память для других приложений и ядра.

  Минусы понятия файла\раздела подкачки:

  - По сравнению с оперативной памятью диски довольно медленные. В памяти обработка происходит в пределах наносекунд, в дисках уже милисекунды. То есть разница в десятки тысяч раз.
    И чем больше операций подкачки - тем медленнее работает система. Или же случаи, когда страница выгружается, а затем снова заменяется.  
    То есть система пытается найти баланс между свободной памятью и поддержкой работы приложений, и скачет туда сюда. И тут поможет скорее только добавление оперативки.

  По поводу самой подкачки - это может быть как файл подкачки. Так и раздел подкачки.  
  **Раздел подкачки** - это, собственно, отдельный раздел диска исключительно для файла подкачки. Никакие другие файлы там не могут находиться.  
  **Файл подкачки** - это специальный файл в файловой системе.  
  Через команду `swapon -s` можно увидеть информацию о подкачке, в том числе раздел это или файл.

  ```
  Filename  Type       Size       Used Priority
  /dev/sda5 partition  859436  0       -1
  ```

  Тут мы видим в качестве примера что это раздел. Что сейчас пространство не использовано.

  В линуксе есть понятие **Swappiness** - это свойство в ядре Linux, которое меняет баланс между подкачкой времени выполнения и удалением страниц из кеша системы.  
  Значение устанавливается от 0 до 100 включительно.  
  Низкое значение означает, что ядро будет стараться избегать использования файла подкачки настолько, насколько это возможно.  
  Высокое - заставит ядро активно использовать пространство подкачки.

  Чем подкачка **не является** - так это аварийной памятью, которая используется, когда что-то идет не так.  
  Есть понятие анонимных страниц. Которые не имеют какого-то резервного хранилища. В случае удаления - их восстановить нельзя.  
  Анонимная память\анонимные страниы это такоие страницы виртуальной памяти, которые не связаны с файлами на диске.  
  Они создаются как бы на лету. И там хранятся временные данные процесса.  
  И вот подкачка это хорошая область где можно сохранять такие страницы.

  И подводя итог - необходимость в использовании swap файла возникает тогда, когда система не может удержать в пмяти необходимый кэш и грязные страницы. То есть это не экстренная память.
  А та паммять, которая позволяет системе эффективнее управлять кэшем и грязными страницы.  
  Что в итоге влияет на общую производительность системы.

  **Кэш памяти** - Это буфер в оперативной памяти, где система хранит копии данных с диска, которые недавно использовались или могут понадобиться в ближайшее время. Нужен для ускорения работы, и уменьшения нагрузки на диск.

  Пример:  
  Когда открывается файл - его содержимое читается с диска и сохраняется. в кэше. Что при дальнейшем повторном открытии системы позволяет системе взять данные из кэша.

  **Грязные страницы (Dirty Pages)** - это те страницы в памяти, которые поменяли, но ещё не записали.

  Пример: При открытии текстового редактора вы можете что-то внести. И вот пока вы файл не сохранили - данные считаются грязными. После записи - страницы становятся "чистыми". (Тут есть нюанс что некоторые редакторы промежуточные данные все равно могут сохранить на диск, но здесь пример больше для понимания).

  И такие данные система удалить не может из памяти, их нужно записать на диск. И большое количество данных может замедлить работу системы.

  **Обобщенный пример:**  
  Можно представить память как ваш стол, за которым работаете.  
  Кэш - это документы, которые вы оставили на столе чтобы иметь к ним быстрый доступ. Их можно в любой момент убрать в ящик. Ну или "удалить" если говорить про систему.
  А грязные страницы это как черновики. И они нам нужны для дальнейшей работы, и прежде чем их убрать - перенести в чистовик. Иначе наша работа насмарку пойдет.

  **Как ядро работает с памятью?**  
  Вся память, которой оперирует система, разбита на страницы. Каждый процесс в системе имеет свое «плоское» адресное пространство. Для каждого процесса система поддерживает карту страниц — какая страница адресного пространства процесса (страница виртуальной памяти) отображена в какую страницу физической памяти - если вообще отображена, разумеется.

  И когда процесс пытается получить доступ к какой-то странице своей памяти, MMU (memory management unit) процессора фактически производит обращение к той странице физической оперативной памяти, куда страница отображена.

  А если страница не отображена ни в какую физическую страницу, то возникает page fault — исключительная ситуация «страница не найдена». При обработке этой ситуации система (ядро) проверяет, имеет ли процесс право получить доступ к своей логической странице: если не имеет (например эта страница заразервирована ядром или находится «за хвостом кучи» процесса) - то процессу придет сигнал `SEGFAULT` — и процесс умрет.

  А если имеет — то ядро выполнит все нужные действия, чтобы восстановить правильное содержимое страницы, и предъявит её процессу - после чего операция успешно выполнится.

  **Примеры поведения**:  
  **Недостаток памяти, ее отсутствие**:  
  При файле подкачки: можем заменить редко используемую анонимную память. Что позволит и память освободить, и оптимизировать частоту обращений в кэш.
  Без файла подкачки: Мы не можем выгрузить анонимную память, поскольку она заблокирована. Что может привести к нетривиальному падению производительности.

  **При скачках при потреблении памяти**  
  При файле подкачки: мы можем отсрочить отрабатывание оом киллера. И успеть с этим что-то сделать.  
  Без подкачки: оом срабатывает быстрее. Плюс заблокированы анонимные страницы памяти.

  Когда памяти становится мало, то алгоритм следующий:

  - Система может попытаться удалить страницы кэша. Их можно просто заново прочитать с диска
  - Грязные страницы перед удалением нужно записать сначала на диск, их просто так система не удалит
  - Анонимные страницы (например данные процессов) можно выгрузить в swap.

  Полезные ссылки для ознакомления:  
  https://basis.gnulinux.pro/ru/latest/basis/49/49._%D0%92%D0%B8%D1%80%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D0%BF%D0%B0%D0%BC%D1%8F%D1%82%D1%8C%2C_swap.html

  Особенно рекомендую эти две стаьи от Артемия:  
  https://habr.com/ru/articles/540104/  
  https://habr.com/ru/post/541214/

---

### Что показывает статус процессов? Какие статусы используются в linux?

- Ответ
  ```bash
  R - процесс исполнется, или ждет своей очереди на исполнение
  S - прерываемый сон - процесс ожидает определенного события или сигнала.
  Нужен, когда процесс нельзя завершить (чтение из файла), ядро переводит на ожидание.
  Ожидать данные от сетевого соединения
  D - непрерывное ожидание, сон. Ждем сигнал от аппаратной части.
  T - остановка процесса, посылаем сигнал STOP. В этом состоянии процессу запрещено выполняться
  Чтобы вернуть к жизни нужно послать CONT
  При завершении процесса он становится зомби
  Z(zombie) - зомби это процесс, который закончил выполнение, но не передал родительскому процессу
  свой код возвращения. Процесс в этом состоянии игнорирует kill.
  Родитель получает код, и освобождает структуру ядра, которое относится к процессу
  Бывает еще когда родительский умирает раньше дочернего. Процесс становится сиротой.
  ```

---

### Что такое зомби-процесс? Как можно создать такой процесс?

- Ответ

  ```bash
  Z(zombie) - зомби это процесс, который закончил выполнение, но не передал родительскому процессу
  свой код возвращения. Процесс в этом состоянии игнорирует kill.

  ```

  ```bash
  #include «stdlib.h>
  #include <sys/types.h>
  #include <unistd.h>
  int main() {
   pid_t child_pid;
   /* Создание дочернего процесса. */
   child_pid = fork();
   if (child_pid > 0) {
    /* Это родительский процесс — делаем минутную паузу. */
    sleep(60);
   } else {
    /* Это дочерний процесс — немедленно завершаем работу. */
    exit(0);
   }
   return 0;
  }
  ```

  Другой вариант создания зомби процесса, попроще:  
   `(sleep 1 & exec /bin/sleep 10)`

  #### Процесс создания зомби-процесса

  Зомби-процесс — это процесс, который завершился, но его статус завершения не был считан родительским процессом. Рассмотрим, как происходит создание зомби-процесса:

  1. Родительский процесс (например, оболочка) создаёт дочерний процесс для выполнения команды в скобках.
  2. Внутри этого дочернего процесса запускается команда `sleep 1` в фоновом режиме.
  3. Сразу после этого выполняется команда `exec /bin/sleep 10`, которая заменяет дочерний процесс на `sleep 10`.
  4. Когда `sleep 1` завершает своё выполнение (через 1 секунду), его родительский процесс уже не может обработать его завершение, так как был заменён на команду `sleep 10`.
  5. В результате, процесс `sleep 1` становится **зомби-процессом**, ожидая, пока его статус завершения будет считан. Однако, этого не происходит, потому что родительский процесс уже выполняет другую программу — `sleep 10`.

  Зомби-процесс будет существовать до тех пор, пока не завершится команда `sleep 10` (через 10 секунд), после чего родительская оболочка сможет обработать завершение всей составной команды.

  Это происходит потому, что команда `exec` заменяет текущий процесс на другой без создания нового процесса, и, следовательно, не может корректно обработать завершение предыдущего дочернего процесса.

  #### Интересная тонкость

  Каждый процесс, при завершении, временно становится зомби до тех пор, пока родительский процесс не считает его статус завершения. Это совершенно нормальное поведение системы, и короткоживущие зомби-процессы не представляют проблемы.

  Однако, ошибки программирования могут привести к накоплению **необрабатываемых зомби-процессов** — процессов, которые завершились, но их статус не был считан родительским процессом. Это может негативно сказаться на работе системы, так как зомби-процессы продолжают занимать записи в таблице процессов.

---

### Чем опасны зомби процессы, какие проблемы они могут создать?

- Ответ
  Зомби не занимают памяти (как [процессы-сироты](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81-%D1%81%D0%B8%D1%80%D0%BE%D1%82%D0%B0)
  ), но блокируют записи в таблице процессов, размер которой ограничен для каждого пользователя и системы в целом.
  При достижении лимита записей все процессы пользователя, от имени которого выполняется создающий зомби родительский процесс, не будут способны создавать новые дочерние процессы. Кроме этого, пользователь, от имени которого выполняется родительский процесс, не сможет зайти на консоль (локальную или удалённую) или выполнить какие-либо команды на уже открытой консоли (потому что для этого командный интерпретатор _sh_ должен создать новый процесс)
  Иногда, если родительский процесс выполняется от имени суперпользователя, для освобождения записей (перезапуска процесса) может потребоваться перезагрузка (причём зачастую — только аппаратным рестартом). Некоторые операционные системы (например, [Sun Solaris](https://ru.wikipedia.org/wiki/Solaris)
  ) при возникновении такой ситуации аварийно завершают часть выполняющихся процессов, восстанавливая работоспособность системы.

---

### Можно ли завершить зомби процесс с помощью SIGKILL?

- Ответ
  Нет, не может. Поскольку зомби процесс уже завершен. И не может принимать сигналов. И тут зомби ожидает что родительский процесс считает код завершения с помощью системного вызова wait.

---

### Что такое SIGCHLD? В какой ситуации процесс может его получить?

- Ответ
  В POSIX-системах SIGCHLD — сигнал, посылаемый при изменении статуса дочернего процесса (завершён, приостановлен или возобновлен).
  Допустим дочерний процесс завершил выполнение и все

---

### Что такое файловый дескриптор, какая информация в нем бывает?

- Ответ
  _Файловый дескриптор_
  - неотрицательное целое число, которое используется в интерфейсе между пространством пользователя и пространством ядра (kernel) для идентификации ресурсов файла / сокета. Когда создаётся новый поток ввода-вывода, ядро возвращает процессу, создавшему поток ввода-вывода, его файловый дескриптор.
    Важно отметить, что файловые дескрипторы не ограничиваются только файлами.
    Они также могут ссылаться на каталоги, сокеты, каналы (pipes), устройства ввода-вывода и даже некоторые специфические для процесса ресурсы, такие как файлы процесса и области памяти.
    Операционная система автоматически создает три файловых дескриптора для каждого процесса: 0 (стандартный ввод), 1 (стандартный вывод) и 2 (стандартный вывод ошибок).

---

### Для чего нужны сигналы? Какие сигналы используются чаще всего? (5 - 10 штук)

- Ответ

  Это уведомление процесса о наступившем событии. Также это способ взаимодйествия между процссами.
  `SIGTERM (15)` - запрос на "мягкое завершение процесса.  
   `SIGKILL (9)` - принудительное завершение процесса.  
   `SIGINT (2)` - прерывание процесса. (Например нажатие Ctrl-C)  
   `SIGSTOP (10)` - приостановка процесса.  
   `SIGCONT (18)` - возобновить работу процесса.  
   `SIGHUP (1)` - перезагрузка конфигурации (например можно так сделать релоад nginx)

  Сигналы `SIGKILL` и `SIGSTOP` нельзя перехватить, блокировать или игнорировать.

---

### Как осуществляется обработка сигналов? Чем отличается SIGTERM от SIGKILL?

- Ответ
  SIGTERM завершает программу. Это как бы мягкое уничтожение. И по умолчанию при вводе команды kill - используется именно он.SIGKILL - немедленное прекращение выполнение процесса. Процесс будет завершен с потоками. Используется как последнее средство. (kill)
  Сигнал SIGKILL передается процессу, чтобы заставить его немедленно завершиться. В отличие от SIGTERM и SIGINT, **этот сигнал не может быть перехвачен или проигнорирован, и процесс получения не может выполнить очистку после получения этого сигнала.**
  Он нужен в критических ситуациях, когда повис процесс.
  Проблема использования sigkill:  
   SIGKILL убивает дочерние процессы.И в этом случае может появиться процесс зомби.  
   Уничтоженный процесс не имеет возможности сообщить родителю о том, что у него был сигнал уничтожения. (kill9)

---

### Какой сигнал получит активный процесс при нажатии Ctrl+C в консоли?

- Ответ
  SIGINT (от англ. signal и interrupt — прервать) — сигнал, применяемый в POSIX-системах для остановки процесса пользователем с терминала.

---

---

### Какие сигналы не могут быть проигнорированы?

- Ответ  
   SIGSTOP - принудительная остановка процесса  
   SIGKILL - немедленное завершение процесса

---

### Что такое load average? Что показывает эта метрика? Почему load average состоит из трёх значений?

- Ответ

  Часто говорят что это средняя загрузка процессора или нагрузка системы, или какие-то циферки.
  Узнать значение la можно разными способами. Например, uptime, top, и другими командами.

  Принято считать, что какое-то стабильное значение этих цифр отражает стабильное поведение системы.
  Появление всплеска может означать появление проблемы в системе. Что-то идет не так, копятся процессы.
  Цифры обозначают нагрузку за определенный период времени. 1, 5 и 15 минут. (Это важно учесть, это все рассчитывается для предыдущего времени. И когда вы заходите на сервер спустя минуту - там может ничего не быть)

  **Определение LA по сути - эта цифра показывает количество процессов в статусе d r (ожидание, запущено соответственно)**
  А дальше уже всё будет зависеть от ситуации.
  Допустим у нас сервер есть где постоянно на диски пишутся резервные копии. Там LA будет высокая скорее всего. Просто потому что есть процессы в статусе d, которые копятся из-за того, что диск занят.
  Но на работу системы в целом это может не влиять вообще.

  Если процессов скопилось много там, где это не ожидается, ну там сервера с сайтами, базами данных, с php-fpm, nginx и прочим таким, то смотрим через `top -cHi -d1` что там именно скопилось.
  И в таких вот случаях сервер может тупить, ибо будут копиться процессы в статусе r. Из-за чего работа сервера будет медленной. Даже по ssh иногда не зайти будет.

  **если коротко** это кол-во процессов и операций ввода/вывода которые находяться в ожидание
  процессорного времени(исполнения процессором) за 1, 5, 15 минут

---

### Можно ли сделать так, чтобы пользователи могли получать информацию только о своих процессах?

- Ответ
  Да, можно, за это отвечает параметр hidepid
  ```bash
  myserver : ~ [0] # cat /proc/mounts | grep proc
  proc /proc proc rw,nosuid,nodev,noexec,relatime,hidepid=2 0 0
  ```

---

### Что такое физическая память?

- Ответ
  **Физическая память** (или **_«ОЗУ»_**, **_«RAM»_**, **_«оперативка»_**) — это энергозависимая память, установленная в компьютере. Для её работы требуется непрерывный поток электричества. Перебои с электропитанием или внезапное выключение компьютера могут привести к стиранию хранящихся в ней данных. Кроме того, эта память является линейно адресуемой. Другими словами, значения адресов памяти увеличиваются линейным образом.
  Запуская и исполняя программы, процессор напрямую обращается к физической памяти.
  Обычно программы хранятся на жестком диске. Время доступа процессора к диску значительно превышает аналогичное время доступа к физической (оперативной) памяти.  
   Чтобы процессор мог выполнять программы быстрее, они сначала помещаются в физическую (оперативную) память. После завершения своей работы, они возвращаются обратно на жесткий диск.  
   Освобожденная таким образом память может быть выделена новой программе. При выполнении данные программы называются **процессами**.

---

### Что такое виртуальная память?

- Ответ
  Виртуальная память (или «логическая память») — это метод управления памятью, осуществляемый операционной системой, который позволяет программам задействовать значительно больше памяти, чем фактически установлено в компьютере.  
   Например, если объем физической памяти компьютера составляет 4 ГБ, а виртуальной 16 ГБ, то программе может быть доступен объем виртуальной памяти вплоть до 16 ГБ.
  Основное различие между физической и виртуальной памятью заключается в том, что физическая память относится к оперативной памяти компьютера, подключенной непосредственно к его материнской плате.  
   Именно в ней находятся выполняемые в данный момент программы.
  А виртуальная память — это метод управления, расширяющий при помощи жесткого диска объем физической памяти, благодаря чему у пользователей появляется возможность запускать программы, требование к памяти которых превышает объем установленной в компьютере физической памяти.
  img https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%201.png

---

### Почему в htop может быть не до конца корректная сводка по потребляемой памяти

- Ответ (спорный)
  Hop не всегда корректно показывает сколько памяти приложение потребляет по факту.
  Пункт VIRT там это скорее параметр, который указывает сколько приложение запросило как бы запросило (про запас), а не сколько использует по факту.
  И в этом плане на этот параметр лучше не полагаться.
  Для анализа используемой памяти лучше использовать скрипт `ps_mem.py`. Он показывает сколько памяти съедается по факту тем или иным процессом, группой процессов.
  Можно найти по ссылке:
  https://github.com/pixelb/ps_mem

---

### Где в системе можно посмотреть сводку по текущему потреблению памяти?

- Ответ

  ```bash
  free -m
  ```

  ```
                 total        used        free      shared  buff/cache   available
  Mem:            3923         309         231           2        3382        3318
  Swap:              0           0           0
  ```

  Эта утилита не показывает физическое количество памяти.  
   Она показывает сколько памяти доступно в системе.  
   То есть физически сколько заняло ядро.

  `total` - 3923 мегабайт - Она показывает сколько памяти у нас в системе.  
   `used` - 309 мегабайт - сколько у нас памяти занимают исполняемые процессы.  
   `free` - 231 мегабайт - ненужная в данный момент память. То есть если надо будет системе - она ее займет.  
   `shared` - 2 мегабайта - shared память для межпроцессорного взаимодействия. Чтобы поделиться памятью из одного процессора в другой.  
   `buff/cache` - буффер - память для компоновки данных. Страничный кэш - это то, с помощью чего мы например можем файлы открывать.

  **Почему линукс съедает память?**
  Потому что процесс который запрашивает данные из файла на диски - он данные выгружает в оперативную память.  
   Чем больше процессов просит данных - тем больше кэша, свободной памяти становится меньше.  
   Однако, единожды загруженный файл в кеш - может там остаться даже если приложение, которое это инициировало - завершилось.  
   Поскольку операции доступа до диска это дорогие по времени операции.  
   И ядро считает, что стоит сохранить какие-то из данных, не чистить их сразу. На тот случай, если кому-то еще эти данные понадобятся.

  Итого свободная память - это та память которая ни нужна ни для кэша, ни для чего-то ещё.  
   `available` - 3381 мегабайт может быть доступно в случае необходимости.  
   Если available нет, то его в примерном виде можно посчитать так: free + 70% от кэша.  
   Ибо не во всех дистрибутивах этот показатель есть.

  **Какие ситуации будут указывать на возможную проблему?**

  - Available память или ( free -/+ buffers/cache ) близки к нулю или очень маленькое значение.
  - В логах ядра есть сообщения `OutOfMemory`. (`dmesg -T | grep out of memory`)

---

### Как работает оом киллер и для чего нужен? Out of memory, oom

- Ответ
  Когда на вашем Linux-компьютере заканчивается память, ядро вызывает Убийцу нехватки памяти (OOM) для освобождения памяти. Это часто встречается на серверах, на которых запущен ряд процессов с интенсивным использованием памяти.
  Оом киллер освобождает память для спасения системы, но чтобы процессы освобождаемые были наименее важны для системы.
  У нас не только физическая и виртуальная память может закончиться. А если процесс потребляет страницу определенного размера, то могут быть не очень хорошие вещи.
  Ядро Linux дает оценку каждому запущенному процессу, называемому **oom_score**, которая показывает, насколько вероятно, что он будет остановлен в случае нехватки доступной памяти.
  Оценка пропорциональна количеству памяти, используемой процессом. Оценка - 10% процентов памяти, используемой процессом. Таким образом, максимальная оценка составляет 100% x 10 = 1000.
  [https://github.com/hightemp/docLinux/blob/master/articles/Linux OOM killer - выживание.md](https://github.com/hightemp/docLinux/blob/master/articles/Linux%20OOM%20killer%20-%20%D0%B2%D1%8B%D0%B6%D0%B8%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5.md)

---

### Как процессы в системе взаимодействуют между собой?

- Ответ
  **Трубы(пайпы '|')** — связь между двумя взаимосвязанными процессами. Механизм является полудуплексным, что означает, что первый процесс связан со вторым процессом. Для достижения полного дуплекса, т. Е. Для взаимодействия второго процесса с первым процессом требуется другой канал.
  **FIFO** — Связь между двумя не связанными процессами. FIFO — это полный дуплекс, что означает, что первый процесс может взаимодействовать со вторым процессом и наоборот одновременно.
  **Очереди сообщений** — связь между двумя или более процессами с полной дуплексной пропускной способностью. Процессы будут связываться друг с другом, отправляя сообщение и извлекая его из очереди. Полученное сообщение больше не доступно в очереди.
  **Совместно используемая память.** Связь между двумя или более процессами достигается за счет совместного использования памяти всеми процессами. Совместно используемая память должна быть защищена друг от друга путем синхронизации доступа ко всем процессам.
  **Семафоры** — семафоры предназначены для синхронизации доступа к нескольким процессам. Когда один процесс хочет получить доступ к памяти (для чтения или записи), он должен быть заблокирован (или защищен) и освобожден при удалении доступа. Это должно быть повторено всеми процессами для защиты данных.
  **Сигналы** — Сигнал — это механизм связи между несколькими процессами посредством сигнализации. Это означает, что исходный процесс отправит сигнал (распознанный по номеру), а целевой процесс обработает его соответствующим образом.
  **Примечание** Почти все программы в этом руководстве основаны на системных вызовах в операционной системе Linux (выполняется в Ubuntu).

---

### `a=5; true | { true && a=10; }` чему будет равно a?

- Ответ будет 5.
  Потому что каждая команда конвейера исполняется в отдельной подоболочке (SubShell)
  ```
  nparamonov@peka:~$ a=5; true | { true && a=10; echo $a; }
  10
  nparamonov@peka:~$ echo $a
  5
  ```

---

### Что такое QEMU

- Ответ
  Это виртуализированный эмулятор, который запускает программы и ОС, созданные для одной машины на другой машине в процессе эмуляции машины. Он может достичь очень хорошей производительности с помощью динамического перевода.
  QEMU (Quick Emulator) – эмулятор различных устройств, который позволяет запускать операционные системы, предназначенные под одну архитектуру, на другой (например, ARM –> x86). Кроме процессора, QEMU эмулирует различные периферийные устройства: сетевые карты, HDD, видео карты, PCI, USB и пр.

---

### Что такое KVM (гипервизор)

- Ответ
  KVM (Kernel-based Virtual Machine) – гипервизор (VMM – Virtual Machine Manager), работающий в виде модуля на ОС Linux. Гипервизор нужен для того, чтобы запускать некий софт в несуществующей (виртуальной) среде и при этом, скрывать от этого софта реальное физическое железо, на котором этот софт работает. Гипервизор работает в роли «прокладки» между физическим железом (хостом) и виртуальной ОС (гостем).

---

### Что такое qemu-kvm?

- Ответ
  KVM предоставляет доступ гостям к Ring 0 и использует QEMU для эмуляции I/O (процессор, диски, сеть, видео, PCI, USB, серийные порты и т.д., которые «видят» и с которыми работают гости).
  Бинарный программный код на процессорах работает не просто так, а располагается на разных уровнях (кольцах / Protection rings) с разными уровнями доступа к данным, от самого привилегированного (Ring 0), до самого ограниченного, зарегулированного и «с закрученными гайками» (Ring 3).

---

### Что такое iowait и почему он может появляться?

- **Ответ**
  iowait это показатель, показывающий процентное соотношение времени процессора, которое он потратил на ожидание ввода-вывода.
  Высокий показатель может сказать о том, что система ограничена возможностями дисковой памяти. Выполняется много операций ввода-вывода. Это замедляет систему.
  Конкретно это обычно означает что блочные устройства работают медленно или они переполнены.
  Замеряется в количестве потоков, которые ждут работы.

---

## Диски и файловая система

**Что такое блочные устройства? Какие элементарные операции можно с ними производить?**

- Ответ
  Блочное устройство представляет собой уровень абстракции, описывающий любое устройство хранения информации, которое может быть разбито на блоки определенного размера; доступ к каждому блоку осуществляется независимо от доступа к другим блокам.
  Такой доступ часто называют произвольным доступом.
  Иными словами блочные устройства нужны тогда, когда используется передача большого объема данных.
  - Сюда входят RAM-диски, компакт диски, накопители на магнитах
  - Доступ также осуществляется через спец файлы интерфейсы в `dev`.
  - На блочных устройствах как правило файловые системы.
  - Блочные устройства представлены часто как множество блоков.
  - Один блок кратен степени двух и равен килобайту данных.
  - Это позволяет линуксу читать и писать как в символьные устройства, так и в блочные.
  - Разница в том, что передается блок данных, а не байт.
  - Для пользователя это незаметно.
  - Используется для монтирования файловых систем.
    Через `lsblk` можно посмотреть такие устройства.  
     Данные передаются блоками. Как правило, кратный размер 256 байт  
     Можно записывать считывать, разделы создавать.
    Блочные устройства не работают напрямую с системными вызовами.
    И в случае блочных устройств их взаимосвязь обеспечивается системой управления файлами и подсистемой плочного устройства.
    Эти подсистемы нужны чтобы подготовить ресурсы (буферы) драйвера устройства. Сохранять недавно прочитанные устйроства в кэш буфере, упорядочивание операций чтения и записи для повышения производительности.

### Что такое символьные устройства? Какие элементарные операции с ними можно производить?

- Ответ
  Один из типов устройств.
  Используется для медленных устройств, у которых происходит обмен небольшим объемом данных. И доступ к ним не требует частых поисковых запросов.
  Примеры таких устройств: мышь, клавиатура, последовательные порты.
  В этом случае данные передаются последовательно, байт за байтом.

  Для этих устройств системные вызовы идут напрямую к драйверам устройств.

---

### Что такое major and minor numbers блочных устройств, чему они соответствуют?

- Ответ
  На примере вывода:
  ```bash
  crw-rw-rw- 1 root   root    1, 3   Feb 23 1999  null
   crw------- 1 root   root   10, 1   Feb 23 1999  psaux
   crw------- 1 rubini tty     4, 1   Aug 16 22:22 tty1
   crw-rw-rw- 1 root   dialout 4, 64  Jun 30 11:19 ttyS0
   crw-rw-rw- 1 root   dialout 4, 65  Aug 16 00:00 ttyS1
   crw------- 1 root   sys     7, 1   Feb 23 1999  vcs1
   crw------- 1 root   sys     7, 129 Feb 23 1999  vcsa1
   crw-rw-rw- 1 root   root    1, 5   Feb 23 1999  zero
  ```
  Цифры 1, 10, 4 и 7 - старшие, мажорные номера.
  Цифры 1, 3, 5, 64, 65 и 129 - минорные номера
  Старший номер идентифицирует драйвер, который связан с устройством.
  `null` и `zero` управляются драйвером 1.
  `tty1`, `ttyS0`, `ttyS1` - управляются драйвером четыре. Это виртуальные консоли и терминалы.
  Как правило один старший номер - один драйвер
  Младший же номер используется ядром что бы определить о каком устройстве идет речь.
  И можно получить ссылку на устройство через ядро. Само ядро ничего про них не знает, знают только то, что здесь ссылаются на устройства, которыми драйвер управляют.

---

### Что такое файловая система? Для чего она нужна?

- Ответ

  **Файловая система** — это способ организации данных на диске, который разделяет данные на отдельные части, называемые файлами. Она также управляет метаданными этих файлов, такими как их имена, разрешения и другие атрибуты.

  Операционная система должна поддерживать файловую систему, чтобы она могла отображать её содержимое, открывать файлы и сохранять их. Если операционная система не распознаёт файловую систему, вы можете установить специальный драйвер, который обеспечит её поддержку.

  #### Файловая система как система хранения

  Файловую систему на компьютере можно сравнить с системой хранения документов. Биты данных на компьютере называются "файлами", и они организованы в "файловую систему", как бумажные файлы организуются в файловые шкафы. Файловые системы обеспечивают различные методы организации этих файлов и хранения данных, и каждый из них имеет свои особенности.

  Существуют разные виды файловых систем, и каждая операционная система может поддерживать разные типы для работы с файлами.

  Для более подробного объяснения, можно ознакомиться с материалом по ссылке:  
   [Подробнее о файловых системах](https://windows-school.ru/blog/kompjuteru_nuzhna_fajlovaja_sistema/2018-08-03-155)

---

### Как создать файловую систему на блочном устройстве? Какие параметры можно задать при создании?

- Ответ

  Создание файловой системы на блочном устройстве можно сделать с помощью команды `mkfs` (make file system).  
   Эта команда обычно используется вместе с типом файловой системы, который вы хотите создать, например, ext4, ext3, xfs и т.д.

  Вот пример команды, которая создает файловую систему ext4 на блочном устройстве `/dev/sdb1`:

  ```bash
  mkfs -t ext4 /dev/sdb1
  ```

  При создании файловой системы можно задать различные параметры, в зависимости от типа файловой системы. Например, для файловой системы ext4 можно задать следующие параметры:

  - `-L label` : задает метку для файловой системы.
  - `-m reserved-blocks-percentage` : задает процент блоков, зарезервированных для суперпользователя.
  - `-E extended-options` : задает расширенные параметры, такие как stride, stripe-width и т.д.
  - `-b block-size` : задает размер блока в байтах (по умолчанию 4096).
  - `-N number-of-inodes` : задает количество индексных дескрипторов (inode) в файловой системе.

  Но для той или иной файловой системы команды и ключи могут быть другими. Так что смотрите какая фс.

---

### Что такое **inodes айноды**

- Ответ
  **Inode** (индексный дескриптор) - структура данных, в которой хранятся метаданные файла и перечислены блоки с данными файла.
  Хранит всю информацию, кроме имени файла и данных.
  Каждый файл в данном каталоге ( по факту таблица с индексами ( inumber ) ) является записью с именем файла и номером индекса.
  Вся остальная информация о файле извлекается из таблицы индексов путем ссылки на номер индекса.
  Номера inodes уникальны на уровне раздела. Каждый раздел имеет собственную таблицу индексов.
  Если у вас закончились inode, вы не можете создавать новые файлы, даже если у вас есть свободное
  место на данном разделе.
  Inodes хранят метаданные о файле, к которому они относятся.
  Эти метаданные содержат всю информацию об указанном файле:
  - Размер.
  - Разрешение.
  - Владелец/группа.
  - Расположение жесткого диска.
  - Дата/время.
  - Любая другая необходимая информация.
    Чтобы увеличить количество inode, нужно увеличить размер файловой системы,
    ведь количество инодов фиксированное и оно задается при создании файловой системы.
    Значит увеличение файловой системы = увеличение количества инодов.
    Существуют файловые системы с динамическим количеством инодов, одна из которых - XFS.
    Динамические иноды отличаются от статических тем, что они динамически создаются по
    мере необходимости и могут делать это автоматически, но это требует более сложных механизмов отслеживания.

---

### Где физически находятся inodes айноды

- Ответ
  Будет зависеть от файловой системы. Например, в ext2, ext3 хранится перед блоками данных. Это атрибут не диска, а файловой системы.
  иноды хранятся в таблицах инодов, и в каждой группе блоков в разделе есть таблица инодов.
  Может быть каталог инодов и имен, которые с ним связаны. Но это также будет зависеть от файловой системы. В fat32 их нет
  images https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%202.png
- Краткий ответ
  Имена inodes (имена файлов, каталогов, устройств и т. Д.) Хранятся на диске в каталогах. В каталоге хранятся только имена и соответствующие номера inode; Фактическое дисковое пространство для именованных данных хранится в пронумерованном индексном узле, а не в каталоге.
  Айнода просто указывает на файл и каталог

---

### По какой причине и на какого типа системах айноды могут закончиться? И к чему это может привести?

- Ответ
  Не будет возможности создания файла
  Зависит от размера блока, на который жесткий диск бьется. И от размера жесткого диска. И также могут разные файловые системы так работать.

---

### Какая файловая система бывает динамическими айнодами и что это такое, зачем нужно?

- Ответ
  Динамические айноды это тот подход, при котором количество айнод не фиксируется при создании файловой системы.  
   Что позволяет изменить их до нужного нам количества.

  В отличие от других файловых систем, где это нужно заранее резервировать.  
   Поскольку в этом случае придется создавать новую файловую систему, раздел с нужным нам количеством данных.

  Как правило такие файловые системы хорошо подходят для систем, где ожидается большое количество файлов.

  Примеры таких файловых систем:  
   XFS, ZFS, BTRFS

---

### Где хранится информация об именах файлов, директорий?

- Ответ
  - Inodes не содержат имён файлов, только другие метаданные файла.
  - Каталоги Unix представляют собой списки ассоциативных структур, каждая из которых содержит одно имя файла и один номер индекса.
  - Драйвер файловой системы должен найти каталог, ищущий определенное имя файла, а затем преобразовать имя файла в правильный соответствующий номер индекса.
    Таким образом имя файла/директории хранится в информационной структуре каталогов.
    ![https://github.com/rmntrvn/adm_linux_ops_questions/raw/master/questions/imgs/inf_struct_catalogs.gif](https://github.com/rmntrvn/adm_linux_ops_questions/raw/master/questions/imgs/inf_struct_catalogs.gif)

---

### Каким образом осуществляется монтирование ФС? Как можно посмотреть список примонтированных ФС? (2 - 3 способа)

- Ответ
  ```bash
  mkfs -t ext3 /dev/hda8
  ```
  `mount` - показать все файловые системы
  `mount -t ext4` - покажет ext4 файловые системы
  Если нужно примонтировать usb
  Создаем файлик и монтируем
  ```bash
  sudo mkdir -p /media/usb
  sudo mount /dev/sdd1 /media/usb
  ```

---

### Что такое псевдофайловая система?

- Ответ

  «Псевдо» означает ложь, притворяться. Таким образом, «псевдофайловая система» означает файловую систему, которая не имеет _фактических_ файлов - скорее, она имеет виртуальные записи, которые сама файловая система создает на месте.

  Можно сказать это интерфейс ядра linux.

  Например, `/proc` во многих ОС - это procfs, который динамически генерирует каталоги для каждого процесса.
  Точно так же `/sys` в Linux генерирует файлы и каталоги для представления аппаратных схем. Есть FUSE на основе псевдо-файловая система для _многих_ вещей.

  `/dev` может быть реальной файловой системой (просто подкаталогом `/`) или виртуальной псевдофайловой системой (например, devfs), или средней точкой, такой как Linux devtmpfs (которая является полной файловой системой в памяти, но все же создает узлы устройства из нигде).

  Основное предназначение современных VFS — организация единого интерфейса доступа пользователя к различным файловым системам, [драйверы](https://ru.wikipedia.org/wiki/%D0%94%D1%80%D0%B0%D0%B9%D0%B2%D0%B5%D1%80)
  которых загружены в память компьютера. Для реализации этой цели от ядра [операционной системы](https://ru.wikipedia.org/wiki/%D0%9E%D0%BF%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B0)
  требуется создание единого [программного интерфейса](https://ru.wikipedia.org/wiki/API)
  внутренних вызовов ядра

  Если говорить о том, где хранится `proc`, то это **представление** структуры ядра. И можно сказать, что содержимое хранится в памяти ядра, то есть в ОЗУ.

---

### Какие проблемы могут возникать с файловой системой и жёстким диском? Можно ли восстановить ФС при незначительном повреждении её структуры? Как это сделать?

- Ответ

  #### Восстановление файловых систем и инструменты для проверки

  Если автоматическая проверка при загрузке не может восстановить согласованность файловой системы, система обычно переходит в однопользовательский режим и выводит сообщение с указаниями для ручного запуска утилиты `fsck`. Для файловой системы **ext2**, которая не поддерживает журналирование, вам может быть предложена серия вопросов для подтверждения операций восстановления. Рекомендуется следовать предложениям `fsck`, отвечая "y" для подтверждения операций. После перезагрузки системы обязательно проверьте, не пропали ли какие-либо файлы или данные.

  #### Ручная проверка файловой системы

  Если вы подозреваете порчу данных или хотите вручную проверить файловую систему, большинство утилит требует предварительного размонтирования файловой системы. Однако размонтировать корневую файловую систему работающей системы невозможно. В этом случае можно перейти в однопользовательский режим (используя команду `telinit 1`), затем перемонтировать корневую файловую систему в режиме «только чтение» и выполнить проверку согласованности. Лучший способ проверки файловых систем — это загрузка с резервной системы (например, с CD-диска или USB-накопителя) и проведение проверки в размонтированном состоянии.

  #### Продвинутые инструменты

  Существуют более функциональные инструменты для проверки и восстановления файловых систем. Правила их использования можно найти в документации (`man`), а также в **Linux Documentation Project**. Большинство этих команд требуют размонтированной файловой системы, хотя некоторые функции могут работать и с файловыми системами, смонтированными в режиме «только чтение».

  **Важно**: перед любыми операциями по восстановлению обязательно создавайте резервную копию файловой системы.

  #### Инструменты для файловых систем ext2 и ext3

  - **tune2fs**  
    Настраивает параметры файловых систем **ext2** и **ext3**. Может добавлять журнал к системе ext2, преобразуя её в **ext3**, а также выводит или задаёт максимальное число монтирований перед проверкой. Можно также задать метку и управлять дополнительными опциями.

  - **dumpe2fs**  
    Выводит информацию о суперблоках и группах блоков в файловых системах **ext2** и **ext3**.

  - **debugfs**  
    Интерактивная утилита для отладки файловых систем **ext2** и **ext3**. Используется для проверки и изменения состояния файловой системы.

  #### Инструменты для файловых систем ReiserFS

  - **reiserfstune**  
    Выводит и настраивает параметры файловой системы **ReiserFS**.

  - **debugreiserfs**  
    Выполняет функции, аналогичные `dumpe2fs` и `debugfs`, для файловой системы **ReiserFS**.

  #### Инструменты для файловой системы XFS

  - **xfs_info**  
    Выводит информацию о файловой системе **XFS**.

  - **xfs_growfs**  
    Расширяет файловую систему **XFS**, если имеется дополнительное дисковое пространство.

  - **xfs_admin**  
    Изменяет параметры файловой системы **XFS**.

  - **xfs_repair**  
    Восстанавливает файловую систему **XFS**, если стандартные проверки при монтировании не могут восстановить её целостность.

  - **xfs_db**  
    Проверяет и отлаживает файловую систему **XFS**.

---

### Какую файловую систему выбрать ext4 или xfs?

- Ответ
  XFS поддерживает очень большие разделы и файлы.
  Также она хорошо работает при многопоточной нагрузке параллельной записи и чтения.
  Не очень подходит для однопоточных нагрузок с большим количеством метаданных. Например если один поток создает и удаляет большое количество мелких файлов.xfs поддерживает динамические inod-ы. В xfs они динамические, и их можно добавить.
  Ограничение системного раздела - 500TB
  В xfs можно потерять все данные, если сбилось что-то в момент записи на диск.
  Да и развернуть бэкап может не получиться, xfs разный может быть на серверах.

  ext4 поддерживает разделы до 50TB. Позволяет уменьшить созданный раздел.
  Лучше себя проявляет на медленных дисках с точки зрения пропускной способности.

  Итог:
  Если много потоков последовательной записи или чтения с большим потреблением cpu в виде мелких файлов, и много метаданных то лучше ext4.

  Если у нас параллельная нагрузка в несколько потоков с большими файлами - лучше xfs.

  https://access.redhat.com/articles/3129891

  По своему опыту скажу - что xfs дисковые аварии в облаках плохо переживает. Потом сложно будет диск привести в рабочее состояние. То и дело будут отвалы, и проверки будут показывать ошибки.

---

### Как определить, на каком физическом жёстком диске находится раздел с файловой системой? Как можно идентифицировать этот носитель без выключения сервера?

- Ответ

  Посмотреть название блочного устройства нужного можно например с помощью команды:
  `mount | grep " $(stat -c%m /home) " | awk '{print $1}'`

  А дальше на основе полученной информации можно выудить фирму, серийный номер и размер диска.
  `smartctl -a /dev/sda | grep -e "Serial Number" -e "Device Model" -e "Model Family" -e "User Capacity"`

---

**Какую файловую систему Вы бы выбрали для работы с большим количеством файлов?**

- Ответ
  ext4, она лучше справляется с большим количеством файлов, метаданных

---

### Как узнать, какими процессами используется раздел?

- Ответ
  `lsof | grep /media/whatever`
  `fuser -mv /path/to/mountpoint`

---

### Для чего необходимы файлы /etc/fstab, /etc/mtab, /etc/mdadm/mdadm.conf?

- Ответ
  При включении главный диск смонтирован в корень. Загрузочный в boot.
  Дополнительные диски можно увидеть в `mnt/*`  
   Информация об этих монтированиях хранится в файле `/etc/fstab`
  Система автоматом монтирует диски на основании тех данных, которые берет их этого файла.
  То есть монтирование происходит во время загрузки
  `/etc/mtab` – это файл, который содержит список уже смонтированных файловых систем.
  Поэтому, когда вы запускаете команду «df», она обращается к этому файлу для генерации вывода.
  Файл mtab содержит софт ссылку на файл /proc/self/mounts.
  [https://zalinux.ru/?p=4895](https://zalinux.ru/?p=4895)
  mdadm - настройки подсистемы софтового рейда

---

### Отличие хардлинков от симлинков hardlinks symlinks

- **Ответ определения**
  Хардлинк - жесткая ссылка. По своей сути является тем же файлом на который ссылается. Также счетчик в айнодах есть. Цифра 1 это оно. Счетчик имен одного и того же файла.
  ```
  ls -lih | grep file
  475949 -rw-r--r--  1 root     setevoy     0B Aug 13 11:51 file1
  475950 -rw-r--r--  1 root     setevoy     0B Aug 13 11:51 file2
  475951 -rw-r--r--  1 root     setevoy     0B Aug 13 11:51 file3
  ```
  Симлинк - магкая ссылка. При ее создании создается новый объект на существующий файл файловой системы.
  Отличить можно по наличию буквы l в выводе команды ls например:
  ```
  ls -lih | grep sym
  475948 lrwxr-xr-x  1 root     setevoy     5B Aug 13 12:02 symlink1 -> file1
  ```
- **Ключевые отличия**
  - `hardlink` не может указывать на файл в другой файловой системе (так как `inode` может принадлежать только одной ФС), а `symlink` – может.
  - при редактировании файла-ссылки в случае с `hardlink`ом – изменятся оба файла, так как это один и тот же объект, а в случае с `symlink`а – можно изменять его имя, атрибуты, направить его на другой файл и при этом оригинальный файл не будет затронут (но учтите, что если вы откроете файл симлинка для редактирования – то измените оригинальный файл, т.к. по сути вы откроете для редактирования именно его)
  - жёсткая ссылка не может указывать на на каталог
  - При удалении `hardlink`
    -а – файл будет существовать до тех пор, пока есть хотя бы 1 `hardlink`
    на него, но может “менять каталог размещения”, если был удалён “исходный” файл, но остался файл-`hardlink`
    в другом месте. При удалении же файла, на который указывает `symlink`
    – файл-ссылка просто станет нерабочим.

---

### Что такое RAID? Какие основные типы RAID существуют, чем они отличаются?

- Ответ

  **RAID** (Redundant Array of Independent Disks/Избыточный массив независимых дисков) - это технология,
  которая позволяет объеденить несколько независимых физических дисков в одну сущность.

  В работе с дисками есть две проблемы

  - Низкая скорость чтения\записи
  - Выход дисков из строя и потеря данных

  И это всё решается с помощью технологии RAID.

  Существуют следующие уровни спецификации RAID: 1,2,3,4,5,6,0. Кроме того, существуют комбинации: 01,10,50,05,60,06. Существуют аппаратные и программные RAID-массивы.

  - Программные массивы создаются уже после установки Операционной Системы средствами программных продуктов и утилит, что и является главным недостатком таких дисковых массивов.
  - Аппаратные RAID’ы создают дисковый массив до установки Операционной системы и от неё не зависят.

  **RAID 0** - чередование

  **RAID 1** - зеркалирование

  **RAID 5** - чередование с четностью

  **RAID 6** - чередование с двойной четностью

  **RAID 10** - совмещение зеркалирования и чередования

  **Уровень RAID 0 - Чередование**

  В системе **RAID 0** данные разделяются на блоки, которые записываются на все диски в массиве. При одновременном использовании нескольких дисков (как минимум 2) это обеспечивает превосходную производительность ввода-вывода. Достигается это за счёт того что данные передаются контроллерам дисков по быстрой шине одновременно, и диски записывают данные на свои блины или чипы одновременно. Таким образом, эффективная скорость записи может вырасти кратно до числа дисков. Эту производительность можно повысить, используя несколько контроллеров, в идеале один контроллер на диск.

  img https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%203.png

  **Преимущества**

  - RAID 0 обеспечивает высокую производительность как в операциях чтения, так и записи. Нет никаких накладных расходов, вызванных контролем четности.
  - Используется весь объем памяти, накладных расходов нет.
  - Технология проста в реализации.

  **Недостатки**

  - RAID 0 не отказоустойчив.
  - В случае сбоя одного диска все данные в массиве RAID 0 будут потеряны.
  - Он не должен использоваться для критически важных систем.

  **Лучшее применение:**

  RAID 0 идеально подходит для некритического хранения данных, которые должны считываться/записываться с высокой скоростью, например, на ретушь изображений или на станции видеомонтажа.

  Если вы хотите использовать RAID 0 исключительно для объединения емкости хранилищ в одном томе, рассмотрите возможность подключения одного диска в путь к папке другого диска. Это поддерживается в Linux, OS X, а также Windows и имеет то преимущество, что сбой одного диска не влияет на данные второго диска.

  **Уровень RAID 1 - Зеркальное отображение**

  Данные хранятся дважды, записывая их как на основной диск (или набор дисков), так и на зеркальный диск (или набор дисков). В случае сбоя диска контроллер использует основной диск или зеркальный диск для восстановления данных и продолжает работу. Вам нужно как минимум 2 диска для массива RAID 1.

  img https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%204.png

  **Преимущества**

  - RAID 1 предлагает отличную скорость чтения и скорость записи, сопоставимую с одиночным диском.
  - В случае сбоя диска данные не нужно перестраивать, их просто нужно скопировать на новый диск.
  - RAID 1 - очень простая технология.

  **Недостатки**

  - Основным недостатком является то, что эффективная емкость хранилища составляет только половину от общей емкости диска, поскольку все данные записываются дважды.
  - Программные решения RAID 1 не всегда допускают горячую замену неисправного диска. Это означает, что неисправный диск можно заменить только после выключения компьютера, к которому он подключен.
  - Для серверов, которые используются одновременно многими людьми, это может быть неприемлемо. Такие системы обычно используют аппаратные контроллеры, которые поддерживают горячую замену.

  **Идеальное использование**

  RAID-1 идеально подходит для критически важных хранилищ, например, для учетных систем. Он также подходит для небольших серверов, в которых будут использоваться только два диска с данными.

  **RAID уровень 5**

  RAID 5 является наиболее распространенным безопасным уровнем RAID. Требуется как минимум 3 диска, но может работать до 16. Блоки данных распределяются по дискам, и на одном диске записывается контрольная сумма четности всех данных блока. Данные о четности не записываются на фиксированный диск, они распространяются на все диски, как показано на рисунке ниже. Используя данные контроля четности, компьютер может пересчитать данные одного из других блоков данных, если эти данные больше не будут доступны. Это означает, что массив RAID 5 может противостоять отказу одного диска без потери данных или доступа к ним. Хотя RAID 5 может быть реализован программно, рекомендуется аппаратный контроллер. Часто дополнительная кеш-память используется на этих контроллерах для улучшения производительности записи.

  img https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%205.png

  **Преимущества**

  - Транзакции чтения данных очень быстрые, в то время как транзакции записи данных несколько медленнее (из-за четности, которая должна быть рассчитана).
  - В случае сбоя диска у вас по-прежнему есть доступ ко всем данным, даже если неисправный диск заменяется, а контроллер хранилища восстанавливает данные на новом диске.

  **Недостатки**

  - Отказы дисков влияют на пропускную способность, хотя это все еще допустимо.
  - Это сложная технология. Если один из дисков в массиве, использующий диски 4 ТБ, выходит из строя и заменяется, восстановление данных (время восстановления) может занять день или более, в зависимости от нагрузки на массив и скорости контроллера. Если другой диск выйдет из строя в течение этого времени, данные будут потеряны навсегда.
  - При этом нагрузка на каждый из дисков возрастает, поэтому вероятность выхода из строя выше чем у любых других схем, а при выходе из строя одного диска алгоритм восстановления крайне активно работает со всеми дисками, что потенциально может привести к лавинообразному выходу из строя последующих дисков.

  **Идеальное использование**

  RAID 5 — это хорошая универсальная система, которая сочетает в себе эффективное хранилище с превосходной безопасностью и достойной производительностью. Он идеально подходит для файловых серверов и серверов приложений с ограниченным количеством дисков с данными.

  **Уровень RAID 6 - Чередование с двойной четностью**

  RAID 6 похож на RAID 5, но данные о четности записываются на два диска. Это означает, что для него требуется как минимум 4 диска и он может выдержать 2 диска, умирающих одновременно. Вероятность поломки двух дисков в один и тот же момент, конечно, очень мала. Тем не менее, если диск в системах RAID 5 умирает и заменяется новым, для восстановления замененного диска требуются часы или даже больше дня. Если в это время умирает другой диск, вы все равно теряете все свои данные. При использовании RAID 6 массив RAID переживет даже этот второй сбой.

  img https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%206.png

  **Преимущества**

  - Как и в RAID 5, операции чтения данных выполняются очень быстро.
  - Если два диска выйдут из строя, у вас все равно будет доступ ко всем данным, даже если вышедшие из строя диски заменяются. Таким образом, RAID 6 более безопасен, чем RAID 5.

  **Недостатки**

  - Операции записи данных выполняются медленнее RAID 5 из-за дополнительных данных о четности, которые необходимо рассчитать. Производительность записи теоретичски может быть на 20% ниже.
  - Отказы дисков влияют на пропускную способность, хотя это все еще допустимо.
  - Это сложная технология. Восстановление массива, в котором вышел из строя один диск, может занять много времени.

  **Идеальное использование**

  RAID 6 — это хорошая универсальная система, которая сочетает в себе эффективное хранилище с превосходной безопасностью и достойной производительностью. Это предпочтительнее, чем RAID 5 на файловых серверах и серверах приложений, которые используют много больших дисков для хранения данных.

  **RAID уровень 10 - объединение RAID 1 и RAID 0**

  Можно объединить преимущества (и недостатки) RAID 0 и RAID 1 в одной системе. Это вложенная или гибридная конфигурация RAID. Он обеспечивает безопасность путем зеркального отображения всех данных на вторичных дисках, в то же время используя распределение по каждому набору дисков для ускорения передачи данных.

  img https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%207.png

  **Преимущества**

  Если что-то идет не так с одним из дисков в конфигурации RAID 10, время восстановления очень быстрое, поскольку все, что нужно, - это скопировать все данные с выжившего зеркала на новый диск. Это может занять всего 30 минут для дисков емкостью 1 ТБ.

  **Недостатки**

  Половина емкости хранения уходит на зеркалирование, поэтому по сравнению с большими массивами RAID 5 или RAID 6 это дорогой способ обеспечения избыточности.

  **Как насчет уровней RAID 2, 3, 4 и 7?**

  Эти уровни существуют, но они не являются общими (RAID 3 по сути похож на RAID 5, но данные четности всегда записываются на один и тот же диск). В этой статье описывается лишь общая классификация RAID-систем, и отображает общие сведения о технологии объединения накопителей.

  **RAID не заменит резервную копию!**

  Все уровни RAID, кроме RAID 0, обеспечивают защиту от сбоя одного диска. Система RAID 6 продолжит работу, даже при выходе из строя одновременно 2 дисков. Для полной безопасности вам все равно необходимо выполнить резервное копирование данных из системы RAID.

  - Эта резервная копия пригодится, если все диски выйдут из строя одновременно из-за скачка мощности.
  - Это защита от кражи системы хранения.
  - Резервные копии могут храниться вне серверной комнаты или ЦОД, в другом месте. Это может пригодиться в случае чрезвычайного происшествия, масштабного системного сбоя, пожара и т.д.
  - Наиболее важной причиной резервного копирования данных нескольких поколений является ошибка пользователя. Если кто-то случайно удаляет некоторые важные данные, и это остается незамеченным в течение нескольких часов, дней или недель, хороший набор резервных копий гарантирует, что вы все равно сможете сохранить эти файлы.

---

### Какие средства для работы с программными RAID массивами существуют в linux?

- Ответ
  `mdadm`
  [https://www.dmosk.ru/miniinstruktions.php?mini=mdadm](https://www.dmosk.ru/miniinstruktions.php?mini=mdadm)

---

### Что такое LVM? Для решения каких задач он предназначен?

- Ответ
  менеджер, позволяющий управлять логическими томами в системах Linux. Сами логические тома можно собрать из нескольких дисков или разделов дисков. LVM расшифровывается как Logical Volume Manager или по-русски — менеджер логических томов.
  LVM или Logical Volume Manager - это еще один программный уровень абстракции над физическими разделами жесткого диска, который позволяет создавать логические тома для хранения данных без непосредственной переразметки жесткого диска на одном или нескольких жестких дисках. LVM увеличивает удобство работы с жестким диском, аппаратные особенности работы скрываются программным обеспечением, поэтому вы можете изменять размеры дисков, перемещать их на лету, без остановки приложений или размонтирования файловых систем. Это очень удобно на серверах, вы можете добавить еще один диск или расширить существующие lvm тома на лету.

---

### Что такое loop devices? Как их можно использовать?

- Ответ
  В Unix-подобных операционных системах устройство цикла , vnd (диск vnode) или lofi (интерфейс файла цикла) является псевдоустройством, которое делает компьютерный файл доступным как блочное устройство .
  Перед использованием петлевое устройство должно быть подключено к существующему файлу в файловой системе. Ассоциация предоставляет пользователю интерфейс прикладного программирования ( API ), который позволяет использовать файл вместо блочного специального файла (см. Файловую систему устройства ). Таким образом, если файл содержит всю файловую систему, файл может быть смонтирован, как если бы это было дисковое устройство.
  Файлы этого типа часто используются для CD образов ISO и дискет образов. Монтирование файла, содержащего файловую систему, с помощью такого монтирования цикла делает файлы в этой файловой системе доступными. Они появляются в каталоге точки монтирования . Петлевое устройство -
  Петлевое подключение имеет несколько применений. Это удобный метод автономного управления и редактирования образов файловой системы, которые в дальнейшем используются для нормальной работы системы. Сюда входят образы CD или DVD или системы установки. Его можно использовать для установки операционной системы в файловую систему без повторного разбиения диска. Он также обеспечивает постоянное разделение данных, например, при имитации съемных носителей на более быстром и удобном жестком диске или инкапсуляции зашифрованной файловой системы. Петлевое устройство - [https://ru.xcv.wiki/wiki/Loop_device](https://ru.xcv.wiki/wiki/Loop_device)

---

### При создании нового файла система возвращает ошибку no space left device

**no space left on device
несмотря на то, что df
сообщает о наличии свободного места. При каких обстоятельствах может возникнуть описанная ситуация?(inodes)**

- Ответ

  ```bash
  Сначала смотрим свободное место
  df

  Потом иноды, поскольку айноды тоже имеют свойство заканчиваться
  df -i

  ```

---

### df сообщает о наличии 20 Гб занятого пространства, подсчёт занятого файлами места при помощи du даёт результат в 20 Мб. При каких обстоятельствах может возникнуть описанная ситуация?(deleted files)

- Ответ
  При удаленном файле такое может быть. Файловый дескриптор держит файл
  Ищем файл через
  `lsof -a +L1 | grep var | grep httpd`
  При удалении файла, который в этот момент был «занят» процессом — его имя удаляется, но inode — остаётся в файловой системе до тех пор, пока не завершится процесс, который «держит» этот файл.
  Соответственно, что бы «освободить» уже удалённые файлы — необходимо перезапустить процесс, который этот файл держит.

---

### При создании нового файла пользователем система возвращает ошибку no space left on device

несмотря на то, что df сообщает о наличии свободного места; при это
пользователь root может создавать и записывать файлы. При каких обстоятельствах может
возникнуть описанная ситуация?(quotas)\*\*

- Ответ
  Бывает так, что превышается квота
  Для каждого юзера и пользователя она своя может быть, жестко заданная
  ```bash
  #посмотреть квоту юзера
  quota -v user
  ```

---

## Debug

### Сервер не отвечает, как можно получить доступ к серверу, не находясь непосредственно в ЦОДе

- Ответ
  tcpconsole, ipmi, kvm
  Написать тикет в цод, чтобы потыкали

---

### Веб-сервер, работающий на сервере в нашей сети, отдаёт ошибку 502. Каким образом можно найти причину ошибки?

- Ответ
  502 bad gateway, ошибка на стороне вышестоящего сервера. То есть nginx сообщает о том, что получил ответ от другого сервера, к которому он обращался - некорректный или непонятный.
  И тут уже надо копать что там в логах у вышестоящего сервера не так.
  Если брать nginx+apache
  Как минимум нужно посмотреть конфиги nginx, подрубить логгирование. И проверить параметры. Как минимум там должно быть такое:

  ```bash
  server {
      listen 80;
      server_name landing.example.com;

      location / {
  			proxy_pass                  http://my_server;
        proxy_set_header            Host $host;
        proxy_set_header            X-Real-IP $remote_addr;
        proxy_http_version          1.1;
        proxy_set_header            X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header            X-Forwarded-Proto http;
        proxy_redirect              http:// $scheme://;
      }

      access_log /landing-access.log;
      error_log  /landing-error.log info;
  }
  ```

  Обращаем внимание на proxy_pass. Это то, куда у нас пошел запрос.
  А дальше действуем по ситуации. Перезапускаем сервис, смотрим логи этого приложения, или, как в данном случае можно еще посмотреть логи сервера apache.
  Впрочем, это касается всех ошибок 5xx.

---

### В директории находится файл с нечитаемым содержимым. Каким образом можно узнать формат хранения данных и предназначение файла?

- Ответ
  Поможет команда `file`. Она в большинстве случаев показывает что это за файл по своей сути.

  ```bash
  $ file stat-master.zip
  stat-master.zip: Zip archive data, at least v1.0 to extract

  $ file unins000.exe
  unins000.exe: PE32 executable (GUI) Intel 80386, for MS Windows

  $ file -i -b unins000.exe
  application/x-dosexec; charset=binary
  ```

---

### Попытка запуска исполняемого файла завершается ошибкой no such file or directory. Почему?

- Ответ
  Причин подобного поведения несколько
  - Файл не существует.
  - Файл существует, но это символическая ссылка
  - Файл существует, но это 32 битный файл. И нужны библиотеки для его запуска.
  - Иногда из-за символов каких-нибудь, в питоне такое происходит, поудалять символы лишние нужно, в самом файле.
  - Нету интерпретатора в системе

---

### Программа сообщает о том, что не может найти свой конфигурационный файл. Каким образом можно узнать, где она пытается его найти?

- Ответ
  Поможет утилита strace
  line-buffered в данном случае это опция, которая выведет результат как только найдет
  strace -f - отслеживание дочерныих процессов
  ```bash
  strace -f lftp sitename |& grep --line-buffered open | grep /home/akkana
  ```
  Либо в самой программе, если удастся найти параметры вывода проблемы. Как правило это -vvv, verbose
  ```bash
  /usr/sbin/mysqld --verbose --help | grep -A 1 "Default options"
  ```

---

### Что будешь делать если у команды chmod убрали права на исполнение? (chmod -x chmod)

- Ответ
  1. Используем утилиту setfacl. По умолчанию её может не быть в системе, но не проблема установить.
  ```
  setfacl -m u::rwx,g::rx,o::x /usr/bin/chmod
  ```
  2 Можно запустить утилиту chmod, передав её явно динамическому компоновщику. В контексте данной заметки считайте компоновщик интерпретатором для программы chmod. В разных дистрибутивах он может иметь разное название и расположение. Пример для Debian 11:
  ```
  /usr/lib64/ld-linux-x86-64.so.2 /usr/bin/chmod +x /usr/bin/chmod**
  ```
  3 Можно скопировать права с любого исполняемого файла и записать содержимое утилиты chmod в этот файл. Получается рабочая копия chmod.
  Создаём пустой файл с правами утилиты ls.
  ```
  cp --attributes-only /usr/bin/ls ./new_chmod
  ```
  Копируем содержимое утилиты chmod в созданный файл:
  ```
  cat /usr/bin/chmod > ./new_chmod
  ```
  Можно использовать:
  ```
  /new_chmod +x /usr/bin/chmod
  ```
  4 Почти то же самое что и предыдущий вариант только проще:
  ```
  install -m 755 /usr/bin/chmod ./new_chmod
  ```
  или так:
  ```
  rsync --chmod=ugo+x /usr/bin/chmod ./new_chmod
  ```
  5 Если умеете программировать на какой-то языке, то можно с его помощью вернуть бит исполнения. Пример с python:
  ```
  python -c "import os;os.chmod('/usr/bin/chmod', 0755)"
  ```

---

### База сейчас сидит и упирается в диск. И с ней ничего не сделать — больше сервер никто покупать не будет. Как сделать так, чтобы оно работало быстрее прямо сейчас?

- Ответы
  ОПАСНО!!!: нужно выключить fsync, чтобы база не дожидалась записи с данных на диск, а как бы сохраняла.
  Linux может отдавать успешную запись, когда он к себе положил в буфер, а не когда на диск засинкал. Это немного костыльный режим работы, даже скорее опасный, рискованный. Питание вырубят в этот момент, и все навернется. Но зато этот метод ускоряет запись на порядок.

### Почему доступной (available) памяти сейчас 2919, если свободной (free) памяти 843?

- Ответы
  - Total. Эта цифра представляет всю существующую память.
  - Used вычисление общего значения оперативной памяти системы за вычетом выделенной свободной, разделяемой, буферной и кэш-памяти.
    `used = total - free - buff/cache`
  - Free – свободная память в системе.
  - Shared – память, используемая (преимущественно) в tmpfs
  - Buffer, и Cache идентифицируют память, используемую для нужд ядра / операционной системы. Буфер и кеш складываются вместе, а сумма указывается в разделе «buff/cache».
  - Available – примерное количество оперативной памяти, доступное для запуска новых приложений без использования ими раздела подкачки.  
     В отличие от поля free, это поле принимает в расчёт страницу cache и также то, что не вся рекуперируемая (пригодная для повторного использования) память будет возвращена для рекуперации из-за того, что элементы используются в данный момент. (То есть то, что можно потенциально освободить. Кэш, буфер и тп)
    Вот и получается, что доступная память (available) как правило больше или равна свободной памяти (free)

---

### Что такое разделяемая память?

Привести примеры\*\*

- Ответ
  Разделяемая память - это область памяти, которую могут использовать несколько процессов одновременно. Это один из способов межпроцессного взаимодействия, позволяющий различным процессам обмениваться данными без необходимости использования более сложных механизмов, таких как сокеты или каналы.

  Например, клиент и сервер.
  Клиент это терминал ввода. Сервер принимает данные.
  Клиент вводит строку терминала. Строка передеается серверу через сегмент памяти. После чего информация выводится.

  Более глобальные примеры:
  Базы данных. Общая память используется в бд, где ряд процессов обращаются к общим структурам данных, и манипулируют ими.

  Веб сервера. Например, апач. Апач использует общую память для рабочих процесов. Что позволяет разным процессам обслуживать разные запросы.

  Операционные системы. Например, linux использует общую память для IPC, кэширования файловой системы и других задач.

  Подробнее про такую память можно почитать тут:
  https://dev.to/0xog_pg/using-shared-memory-in-linux-1p62

---

### Сервер под нагрузкой тормозит - тяжелые запросы к кассандре и ELK отрабатывают сильно медленнее чем раньше и чем другие аналогичные сервера.

    Мы сняли с сервера нагрузку, но оставили кассандру и ELK запущенными. Надо понять что делает сервер тормозным.

- Ответ

  - Сначала делаем команду top, обратить внимание на sys time и 35% CPU, которое отъедало systemd. Соответственно, что-то там усиленно ядро творило в своем sys time
  - Чтобы увидеть что именно делает systemd можно запустить `strace -c -p 1`, это даст таблицу сисколов, среди которых `waitid` отъедал много ресурсов.(78% CPU времени кушало). Данный системный вызов используется во время ожидания изменения состояния процесса.
    Отсюда предположение - systemd что-то порождает, оно падает, случается waitid и все это добро происходит быстро и в больших кол-вах
  - Далее смотрим что именно systemd может так усиленно плодить: `watch -n 1 ps --ppid 1`. Тут мы видим какие процессы активно форкаются.
    И в таблице вывода замелькали сомнительные `a.out` и `a.sh`
  - Поиск по имени (`find / -name "a.sh" 2`> /dev/null) привел к скрипту /var/games/a.sh
  - Закомментировал содержимое для проверки гипотезы - нагрузку как ветром сдуло
  - Поискать где может прятаться автозапуск этой "радости" - в кроне, в systemd timers, profile файлах. Либо спрятано с особой выдумкой, либо было запущено вами вручную с последующей чисткой history.

---

### допустим у тебя есть бинарник который запускается и сразу падает, у него все файловые дискрипторы пустые, как бы ты искал решение проблемы?

- Ответ

  Есть утилита strace, с помощью которой можно отследить какие вызовы к ядру делает процесс приложения, которое падает
  Её можно использовать следующим образом:

  ```
  strace ./my_crashing_binary
  strace ./my_crashing_binary 2>out.txt
  strace -p 12345 2>out.txt
  ```

  Пример вывода ошибки. Здесь мы видим что идет попытка обращения к файлу, которого нет. По итогу программа падает

  ```
  <snip>
  ...
  write(1, "Hello World\n", 12) = 12
  brk(0) = 0x940e000
  brk(0x942f000) = 0x942f000
  open("/myfile", O_RDONLY) = -1 ENOENT (No such file or directory)
  --- SIGSEGV (Segmentation fault) @ 0 (0) ---
  +++ killed by SIGSEGV (core dumped) +++
  ---
  ```

## СУБД Базы Mysql

### Что такое индексы, зачем они нужны?

- Ответ
  Представьте себе, что у вас есть полочка для книг. При этом изначально эта полочка с книгами пуста. Книги вам то приносят, то уносят, то делают в них какие-то корректировки (к примеру, мемуары или может быть черновики) и тому подобное.
  Так как полочка маленькая, то вы как-то не особо задумывались о какой-либо системе классификации, а просто вставляете книги в любые пустые места.
  Каждый раз когда-то вам или кому-то необходимо найти определенную книгу, возникает необходимость просматривать все книги с самого начала полочки до первой попавшейся (если нужна только одна книга) или полностью все (если нужно собрать все копии). В принципе, для одной полочки это весьма необременительно.
  И нужно придумать систему классификации.
  Например, можно добавлять закладки в каталог.
  Поэтому вы поступаете проще, вы берете каталог, где возможно добавлять листочки. При этом каждую страницу выделяете только под одно название книги, а сами страницы располагаете в каталоге в порядке возрастания названий. Содержание этих страниц весьма просто — вы записываете в каком стеллаже, на какой полке и какой по счету является книга. Если книг несколько, то строчек в этой странице становится несколько.
  Таким образом, чтобы найти одну или все нужные книги по названию, вам достаточно открыть этот каталог и быстро пролистнуть до нужной страницы, а затем пройтись по всем указанным стеллажам. При этом для упрощения, вы также можете первые буквы названий так же индексировать. То есть добавляете наклейку на каждую первую страницу с указанной буквой (таким образом можете сразу перейти, например, к букве «Р», не пролистывая все названия до нее).
  Конечно, для поддержки такой системы требуется дополнительное время, но все же оно существенно меньше, чем попытка найти вслепую книгу из тысячи (пара минут против нескольких часов и более).
- Альтернативный ответ, ссылка на статью
  [https://infostart.ru/1c/articles/444987/](https://infostart.ru/1c/articles/444987/)

---

### Какая будет проблема если проставить много индексов?

- Ответ
  Причина того, что наличие большого количества индексов — это плохо, заключается в том, что это резко увеличивает объем операций записи, которые необходимо выполнить в таблице. Это происходит в нескольких разных местах. Когда происходит запись, данные сначала записываются в журнал транзакций. Когда это происходит, это регистрируется для каждого отдельного индекса, в который выполняется запись. Таким образом, для таблицы с девятью некластеризованными индексами в журнале транзакций выполняется 10 операций записи.
- Другой ответ, более полный

  1. **Накладные затраты при записи данных**

     Очевидно, что для поддержаиня какой-либо дополнительной структуры данных, либо определенной организации данных, требуется совершать дополнительные действия.

     Действий не так много, накладные затраты на них небольшие. Но плохо то, что эти затраты и действия возникают при записи данных. А запись данных происходит в транзакции.

     Хуже если в транзакции происходит и запись и чтение данных (контроль остатков). В этом случае индекс должен быть всегда в актуальном состоянии.

     Затраты на запись или чтение в транзакции намного "дороже" внетранзакционных издержек. Дело в том, что запись может вестись строго последовательно, и время на фиксацию изменений в БД сократить достаточно сложно. Более мощное оборудование тут не всегда помогает.

     Внетранзакционное же чтение данных может вполне успешно выполняться параллельно, при этом в случае увеления количества запросов на чтение данных, к примеру, вследствие роста количества пользователей, то они вполне могут решиться наращиванием аппаратных ресурсов.

  2. **Накладные затраты на обслуживание индексов**
     При интенсивной записи данных в таблицу данные индексов к ней не всегда распологаются на той странице, на которой должны. Появляются "пропуски", физическая структура индексов становится неэффективной. Поэтому иногда бывает необходимо производить дефрагментацию индексов. Производительность запросов к СУБД во время дефрагментации, соответственно, падает. Есть ещё процесс полного перестроения индексов - но в современных версиях MS SQL необходимости выполнения данной операции по регламенту нет.
  3. **Влияние индексов на размер базы**
     Не самое страшное последствие, но так или иначе если база весит 150-200 ГБ, то об этом надо уже задуматься. Для средней OLTP базы размер индексов, как правило, превышает объём самой базы.
     Не верите? Вполне можете воспользоваться какой-либо обработкой вроде этой:
     [//infostart.ru/public/19463/](https://infostart.ru/public/19463/)
     и посмотреть, сколько же в вашей базе места занимают индексы.
  4. **Затраты на создание и поддержание актуальной статистики**
     Статистику в базе нужно регулярно обновлять при интенсивных операциях вставки и обновления. Это занимает вычислительные ресурсы, хоть и не влияет непосредственно на процесс. Рекомендовано и в некоторых БД реализуется автоматически обновление статистики ночью, в период офф-пика, когда executor nodes нельзя полностью гасить, но можно занять их несрочной работой.
     Неактуальная статистика может привести к проблемам производительности системы.
     Но это не значит, что индексы - это плохо, без них СУБД были бы бесполезны.
     **Плохи индексы, которые не используются.**

---

### Как настроить мастер слейв репликацию в мускуле?

- Ответ

  Необходимы 2 сервера: master и slave.

  1. На оба сервера устанавливаем сервер MySQL одинаковой версии.
  2. Включаем сервер базы данных на обоих серверах.
  3. Настраиваем **master** - в `/etc/my.cnf` устанавливаем следующие значения:

  ```bash
  # выбираем ID сервера, произвольное число, лучше начинать с 1
  server-id = 1

  # путь к бинарному логу
  log_bin = /var/log/mysql/mysql-bin.log

  # название Вашей базы данных, которая будет реплицироваться
  binlog_do_db = newdatabase
  ```

  Перезапускаем сервер базы данных.

  4. Подключаемся к **master** серверу, создаем пользователя и назначаем ему права для выполнения репликации.

  ```bash
  mysql -u root -p <пароль root сервера БД>
  GRANT REPLICATION SLAVE ON *.* TO 'slave_user'@'%' IDENTIFIED BY 'password';
  FLUSH PRIVILEGES;
  ```

  5. На master сервере делаем дамп базы данных c блокировкой таблиц.

  ```bash
  mysqldump -u root -p --lock-all-tables newdatabase > newdatabase.sql
  ```

  6. Переносим дамп базы на slave сервер, создаем базу данных с таким же именем и импортируем базу.

  ```bash
  CREATE DATABASE newdatabase;
  mysql -u root -p newdatabase < newdatabase.sql
  ```

  7. Настраиваем slave в `/etc/my.cnf`:

  ```bash
  # ID Слейва, удобно выбирать следующим числом после Мастера
  server-id = 2
  # Путь к relay логу
  relay-log = /var/log/mysql/mysql-relay-bin.log
  # Путь к bin логу на Мастере
  log_bin = /var/log/mysql/mysql-bin.log
  # База данных для репликации
  binlog_do_db = newdatabase
  ```

  Перезапускаем сервер базы данных.

  8. Запускаем репликацию на slave сервере.

  ```bash
  CHANGE MASTER TO MASTER_HOST='10.10.0.1', MASTER_USER='slave_user', MASTER_PASSWORD='password',
  MASTER_LOG_FILE = 'mysql-bin.000001', MASTER_LOG_POS = 107;
  # Указанные значения мы берем из настроек Мастера
  После этого запускаем репликацию на Слейве:
  START SLAVE;
  ```

  9. Проверяем статус репликации:

  ```bash
  SHOW SLAVE STATUSG
  ```

---

### В чем разница между TRUNCATE DELETE и DROP?

- Ответ  
   Тут важно понимать что от базы к базе поведение данных операций может отличаться.

  1. Оператор `DROP` используется для удаления **структуры** таблицы. После удаления индексы, ограничения и триггеры, зависящие от таблицы, также будут удалены, но функции и хранимые процедуры, которые зависят от таблицы, останутся, но станут недействительными. Операция необратимая. Это операция **DDL** (Data Definition Language). Бытовая аналогия - снести целый дом.
  2. Оператор `DELETE` используется для удаления **данных** в таблице, его можно удалить с помощью условий, и все данные в таблице удаляются без условий. Операция откатываемая. Дольше работает, поскольку информация для отката записывается. Блокирует только удаляемые строки, а не всю таблицу. Это операция **DML** (Data Manipulation Language). Бытовая аналогия - выбросить какие-то отдельные вещи из дома.
  3. Оператор `TRUNCATE` используется для удаления всех данных в таблице. Операция быстрая и эффективная, ибо **не хранит подробную операцию для отмены**. Необратимая операция. На время работы блокирует таблицу. Это также операция **DDL**. Бытовая аналогия - выбросить содержимое дома, но оставить сам дом.

  - **DDL** (Data Definition Language) - язык определения данных. Операции изменяют структуру базы данных (CREATE,ALTER,DROP,TRUNCATE)
  - **DML** (Data Manipulation Language) - язык манипулирования данными. То есть работают с содержимым таблиц (SELECT,INSERT,UPDATE,DELETE)

  Основное отличие в том, что **DDL** работают со структурой базы данных и обычно необратимы.  
   А **DML** операции работают с данными внутри таблиц и могут быть отменены до подтверждения транзакции.

---

## Что такое роли в pgsql

- Ответ
  **PostgreSQL** использует концепцию ролей (_roles_) для управления разрешениями на доступ к базе данных.
  Роль можно рассматривать как пользователя базы данных или как группу пользователей, в зависимости от того как роль настроена.
  Роли могут владеть объектами базы данных (например, таблицами) и выдавать другим ролям разрешения на доступ к этим объектам, управляя тем, кто имеет доступ и к каким объектам.
  Кроме того, можно предоставить одной роли _членство_ в другой роли, таким образом одна роль может использовать привилегии других ролей.
  Концепция ролей включает в себя концепцию пользователей ("users") и групп ("groups"). До версии 8.1 в PostgreSQL пользователи и группы были отдельными сущностями, но теперь есть только роли. Любая роль может использоваться в качестве пользователя, группы, и того и другого.

---

### Почему не следует использовать утилиту mysqldump на большой активной базе данных? Какие Вы знаете альтернативы?

- Ответ

  Потому что может произойти блокировка таблиц. И любые изменения данных будут ожидать полного окончания дампа.  
   Из-за этого приложение фактически перестает работать.  
   Поэтому во время снятия дампа нужно отключить блокировку таблиц.

Можно использовать ключ `--single-transaction`, который позволит прочитать базу, и потом уже делать дамп. Это создаст корректный дамп.  
`--skip-lock-tables` - помогает в случаях когда у нас есть движок MYIASAM. И это позволяет избежать несогласованности данных.

---

### Аббревиатура ACID, как расшифровывается?

- Ответ

  - **Atomicity** (Атомарность) - говорит что каждая транзакция является неделимой единицей работы,
    и либо выполняется полностью, либо не выполняется вовсе.
  - **Consistency** (Согласованность) - обеспечивает, что транзакция переводит базу данных из одного согласованного состояния в другое согласованное состояние. То есть, из одного валидного состояния в другое.  
    Допустим, есть правило что баланс счета не должен быть минусовой, Consistency гарантирует, что после транзакции ни один из балансов не будет минусовой
  - **Isolation** (Изоляция) - каждая транзакция должна выполняться изолированно от других транзакций.  
    Допустим две транзакции не могут одновременно работать с одними данными в один момент времени.
  - **Durability** (Долговечность) - после того как транзакция была успешно завершена, изменения должны остаться в базе данных, даже если что-то отъебнет.

---

### Как безопасно удалить или изменить миллион строк в базе данных?

- Ответ

  Если просто в лоб удалять таблицу через DELETE, то мы можем столкнуться с блокировками таблицы. То есть таблица какое-то время будет недоступна.  
  Также можно столкнуться с повышенной нагрузкой на систему, что также замедлит общую производительность запросов.

  1. Создать временную таблицу, с той же структурой, что и у текущей таблицы. Скопировать туда нужные данные. Потом переименовать таблицы. И удалить старую ненужную. В некоторых случаях это быстрее.
  2. Порционное удаление. То есть мы разбиваем удаление по частям, например по 1000 записей. Можно оставить задержку между удалением. (Нужно это делать в транзакции).
  3. Нужно найти время, когда нагрузка на базу минимальная. Как правило, это ночное время.
  4. На всякий случай создать резервную копию базы.

---

### Что такое wal-файл и зачем он нужен?

- Ответ  
  WAL (Write-Ahead Logging) - механизм журналирования в PostgreSQL который записывает все изменения данных перед тем, как они попадут на диск.  
  По сути это страховка для базы данных, помогающая не потерять данные, если что-то пойдет не так.

  Задачи:

  1. Обеспечение целостности и надежности данных

  - В случае сбоя системы или краха данных
  - При внезапном отключении питания
  - При аппаратных проблемах

  2. Репликация

  - Wal используется для синхронизации реплик
  - Обеспечивает последовательное применение изменений

  3. Оптимизация производительности

  - Изменения сначала записываются в wal файл (быстрая последовательная запись)
  - После чего происходит асинхронное обновление основных файлов базы (медленные случайные операции I/O)

  4. Point-in-time-recovery

  - Позволяет восстановить базу данных на любой момент времени
  - Помогает при случайном удалении или повреждении данных
  - Позволяет откатиться к определенной точке

## GITLAB CI/CD

### Каковы ключевые компоненты GitLab CI/CD?

- Ответ

  - Ключевые компоненты включают в себя:

  **Файл .gitlab-ci.yml:**

  - Определяет конфигурацию конвейера
  - Содержит описание всех job, stages, переменных и правил
  - Должен находиться в корне репозитория

  **Runners:**

  - Выполняют задания (jobs)
  - Могут быть shared (общие), group (групповые) или specific (проектные)
  - Поддерживают различные executors (Docker, Shell, Kubernetes и др.)

  **Задания (Jobs) и этапы (Stages):**

  - **Jobs** - отдельные задачи с командами для выполнения
  - **Stages** - группируют jobs и определяют порядок их выполнения
  - Jobs в одном stage выполняются параллельно
  - Stages выполняются последовательно

  **Конвейеры (Pipelines):**

  - Автоматизируют рабочие процессы от написания кода до развертывания
  - Запускаются автоматически при push, merge request или по расписанию
  - Состоят из одного или нескольких stages

  **Пример базовой структуры:**

  ```yaml
  stages:
    - build
    - test
    - deploy

  variables:
    NODE_VERSION: '18'

  build_job:
    stage: build
    script:
      - npm install
      - npm run build
    artifacts:
      paths:
        - dist/

  test_job:
    stage: test
    script:
      - npm run test
    coverage: '/Coverage: \d+\.\d+%/'

  deploy_job:
    stage: deploy
    script:
      - npm run deploy
    only:
      - main
  ```

---

### Что такое before_script и after_script в GitLab CI/CD?/CD?

- Ответ

  - `before_script` - выполняет команды перед основным скриптом каждой job
  - `after_script` - выполняет команды после основного скрипта каждой job

  **Особенности использования:**

  **before_script:**

  - Выполняется в той же shell-сессии, что и script
  - Если завершается с ошибкой, job помечается как failed
  - Переменные, установленные здесь, доступны в script

  **after_script:**

  - Выполняется в отдельной shell-сессии
  - Всегда выполняется, даже если script завершился с ошибкой
  - Переменные из script и before_script недоступны
  - Не влияет на статус job

  **Пример использования:**

  ```yaml
  job_example:
    before_script:
      - echo "Setting up environment"
      - export DATABASE_URL="test://localhost"
      - npm install
    script:
      - echo "Running main script"
      - npm run test
    after_script:
      - echo "Cleaning up"
      - docker stop test-container || true
      - rm -rf temp-files/

  # Глобальные before_script и after_script для всех job
  default:
    before_script:
      - echo "Global setup"
    after_script:
      - echo "Global cleanup"

  # Переопределение глобальных настроек в конкретной job
  custom_job:
    before_script:
      - echo "Custom setup only"
    script:
      - echo "Custom script"
    # after_script наследуется от default
  ```

---

### У вас есть 5 проектов на одном языке программирования. Как организовать пайплайны, чтобы избежать дублирования конфигурации?

- Ответ

  - Для избежания дублирования конфигурации используйте следующие подходы:
    1. **Создание общих шаблонов** - вынесите повторяющиеся задачи (`build`, `test`, `lint`) в отдельный YAML-файл
    2. **Использование `include`** - подключайте общие конфигурации в проектах
    3. **Применение шаблонов** - используйте `extends`, `rules`, переменные окружения

  **Пример структуры:**

  ```yaml
  # common-templates.yml
  .build_template:
    stage: build
    script:
      - npm install
      - npm run build
    artifacts:
      paths:
        - dist/

  .test_template:
    stage: test
    script:
      - npm run test
    coverage: '/Coverage: \d+\.\d+%/'

  # В каждом проекте .gitlab-ci.yml
  include:
    - project: 'templates/ci-templates'
      file: 'common-templates.yml'

  build_job:
    extends: .build_template

  test_job:
    extends: .test_template
  ```

---

### Как запускать тесты только при создании merge request?

- Ответ

  - Используйте директиву `rules` с условием проверки источника пайплайна:

  ```yaml
  test_job:
    stage: test
    script:
      - echo "Running tests for merge request"
      - npm run test
    rules:
      - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  ```

  **Дополнительные варианты контроля:**

  ```yaml
  # Запуск только для MR в определенную ветку
  test_mr_to_main:
    script:
      - npm run test
    rules:
      - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'

  # Запуск при изменении определенных файлов
  test_on_changes:
    script:
      - npm run test
    rules:
      - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
        changes:
          - 'src/**/*'
          - 'tests/**/*'
  ```

  **Документация:** https://docs.gitlab.com/ci/pipelines/merge_request_pipelines/

---

### Если в before_script переопределить переменную, будет ли она доступна в script?pt`?

- Ответ

  - Да, переменная будет доступна. Все секции `before_script`, `script` и `after_script` выполняются в рамках одной shell-сессии в пределах одной job.

  **Пример:**

  ```yaml
  job_with_variable:
    variables:
      ORIGINAL_VAR: 'initial_value'
    before_script:
      - export MODIFIED_VAR="modified_in_before_script"
      - echo "MODIFIED_VAR in before_script: $MODIFIED_VAR"
    script:
      - echo "MODIFIED_VAR in script: $MODIFIED_VAR" # Будет доступна
      - echo "ORIGINAL_VAR: $ORIGINAL_VAR" # Тоже доступна
    after_script:
      - echo "MODIFIED_VAR in after_script: $MODIFIED_VAR" # И здесь тоже
  ```

  **Важно:** Переменные, определенные в одной job, не передаются в другие job без использования артефактов или других механизмов.

---

### Какие существуют способы контроля запуска job в GitLab CI?

- Ответ

  - Существует несколько механизмов для контроля выполнения job:

  **1. Rules (рекомендуемый способ)**

  Наиболее гибкий и современный подход:

  ```yaml
  deploy_job:
    script:
      - echo "Deploying to production"
    rules:
      - if: '$CI_COMMIT_BRANCH == "main"'
      - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
        when: manual
      - when: never
  ```

  **2. Only/Except (устаревший)**

  ```yaml
  build_job:
    script:
      - echo "Building application"
    only:
      - main
      - develop
    except:
      - tags
  ```

  **3. Встроенные переменные**

  - `$CI_COMMIT_BRANCH` - название текущей ветки
  - `$CI_PIPELINE_SOURCE` - источник запуска пайплайна
  - `$CI_COMMIT_TAG` - тег коммита
  - `$CI_MERGE_REQUEST_TARGET_BRANCH_NAME` - целевая ветка MR

  **4. Changes и Paths**

  ```yaml
  test_frontend:
    script:
      - npm run test
    rules:
      - changes:
          - 'frontend/**/*'
          - 'package.json'
  ```

  **5. Manual jobs**

  ```yaml
  deploy_production:
    script:
      - echo "Deploying to production"
    when: manual
    only:
      - main
  ```

  **6.Через `when`**

  - `when: always` - всегда выполнять
  - `when: on_success` - только при успехе предыдущих job (по умолчанию)
  - `when: on_failure` - только при провале предыдущих job
  - `when: manual` - запуск вручную
  - `when: never` - никогда не выполнять

### Что такое кэширование в GitLab CI/CD?

- Ответ

  - Кэширование позволяет сохранять файлы и директории между запусками job или пайплайнов для ускорения выполнения и сокращения времени сборки.

  **Основные принципы:**

  - **Цель** - избежать повторной загрузки зависимостей (node_modules, vendor/, .m2/, etc.)
  - **Область действия** - может использоваться внутри одного пайплайна или между разными пайплайнами
  - **Ключ кэша** - определяет уникальность и условия обновления кэша

  **Пример базового кэширования:**

  ```yaml
  variables:
    npm_config_cache: '$CI_PROJECT_DIR/.npm'

  cache:
    key: '$CI_COMMIT_REF_NAME'
    paths:
      - node_modules/
      - .npm/

  install_dependencies:
    stage: build
    script:
      - npm ci --cache .npm --prefer-offline
    cache:
      key: '$CI_COMMIT_REF_NAME-$CI_JOB_NAME'
      paths:
        - node_modules/
      policy: pull-push # Загружает и сохраняет кэш

  test_job:
    stage: test
    script:
      - npm run test
    cache:
      key: '$CI_COMMIT_REF_NAME-install_dependencies'
      paths:
        - node_modules/
      policy: pull # Только загружает кэш
  ```

  **Стратегии кэширования:**

  ```yaml
  # По содержимому файлов (рекомендуется)
  cache:
    key:
      files:
        - package-lock.json
    paths:
      - node_modules/

  # По ветке
  cache:
    key: "$CI_COMMIT_REF_NAME"
    paths:
      - vendor/

  # Глобальный кэш
  cache:
    key: "global-cache"
    paths:
      - .m2/repository/
  ```

  **Политики кэширования:**

  - `pull-push` (по умолчанию) - загружает перед job, сохраняет после
  - `pull` - только загружает существующий кэш
  - `push` - только сохраняет кэш после выполнения

  **Важные моменты:**

  - Кэш не гарантирован - может быть очищен в любой момент
  - Для критически важных файлов используйте артефакты, а не кэш
  - Кэш работает быстрее артефактов, но менее надежен

## GIT

### Чем `merge` отличается от `rebase`?

- Ответ
  - `git merge` - выполняет слияние коммитов из одной ветки в другую. В этом процессе изменяется только целевая ветка. История исходных веток остается неизменной.
    ![https://github.com/rmntrvn/adm_linux_ops_questions/raw/master/questions/imgs/git-merge.png](https://github.com/rmntrvn/adm_linux_ops_questions/raw/master/questions/imgs/git-merge.png)
    _Преимущества_:
    1. Простота,
    2. Сохраняет полную историю и хронологический порядок,
    3. Поддерживает контекст ветки.
       _Недостатки_:
    4. История коммитов может быть заполнена (загрязнена) множеством коммитов,
    5. Отладка с использованием git bisect может стать сложнее.
  - `git rebase` - сжимает все изменения в один патч. Затем интегрирует патч в целевую ветку. В отличии от _merge_, _rebase_ перезаписывает историю, потому что она передаётся завершенную работу из одной ветки в другую. В процессе устраняется нежелательная история.
    ![https://github.com/rmntrvn/adm_linux_ops_questions/raw/master/questions/imgs/git-rebase.png](https://github.com/rmntrvn/adm_linux_ops_questions/raw/master/questions/imgs/git-rebase.png)
    _Преимущества_:
    1. Упрощает потенциально сложную историю,
    2. Упрощение манипуляций с единственным коммитом,
    3. Избежание слияния коммитов в занятых репозиториях и ветках,
    4. Очищает промежуточные коммиты, делая их одним коммитом, что полезно для DevOps команд.
       _Недостатки_:
    5. Сжатие фич до нескольких коммитов может скрыть контекст
    6. Перемещение публичных репозиториев может быть опасным при работе в команде,
    7. Появляется больше работы,
    8. Для восстановления с удаленными ветками требуется принудительный пуш. Это приводит к обновлению всех веток, имеющих одно и то же имя, как локально, так и удаленно.

---

### Когда нужно использовать `merge`, когда `rebase`?

- Ответ
  Предназначение этих команд git – интеграция изменений из одной ветки в другую, но делают они это по-разному.
  Предположим, у вас сложилась такая ситуация:
  ```
  A <- B <- C    [master]
  ^
   \
    D <- E       [branch]
  ```
  После обычного мержа репозиторий будет выглядеть так:
  ```
  A <- B <- C
  ^         ^
   \         \
    D <- E <- F
  ```
  А после `git rebase`– так:
  ```
  A <- B <- C <- D <- E
  ```
  Rebase указывает на то, что коммиты нужно буквально перенести со старого места на новое.
  Что выбрать?
  - Если вы сомневаетесь, то используйте обычное слияние.
  - Выбор между merge и rebase обусловлен тем, какой вы хотите видеть историю коммитов: линейной или ветвящейся.
    Учитывайте следующие факторы:
  1. Если ветка, в которую вы хотите внести изменения доступна для других разработчиков (например, в open source проекте), не используйте rebase. Эта команда удаляет ветку целиком и приводит к рассинхронизации копий
     репозиториев.
  2. Представляет ли исходная ветка ценность? Некоторые команды работают
     по принципу «одна функция – одна ветка», при этом ветка идентифицирует
     последовательность коммитов. В модели «один разработчик – одна ветка» в
     этом нет особой необходимости, так как автор коммита известен.
  3. Не захотите ли вы вдруг отменить слияние? Возврат rebase значительно затруднен по сравнению с обычным слиянием, а иногда даже невозможен.

---

### Чем отличается git pull и git fetch

- Ответ
  При использовании `pull`, git пытается сделать всё за вас. Он сливает любые внесённые коммиты в ветку, в которой вы сейчас работаете.
  Команда `pull` автоматически сливает коммиты, не давая вам сначала просмотреть их. Если вы не пристально следите за ветками, выполнение этой команды может привести к частым конфликтам.
  При использовании `fetch`, git собирает все коммиты из целевой ветки, которых нет в текущей ветке, и сохраняет их в локальном репозитории. Однако он не сливает их в текущую ветку
- Краткий ответ
  git pull — это, по сути, команда git fetch, после которой сразу же следует git merge.
  Команда git fetch получает изменения с сервера и сохраняет их в каталог refs/remotes/. Это действие (fetch) не влияет на локальные ветки и текущие изменения, просто изменения с удаленного сервера скачиваются в директорию локального репозитария.

---

### Что такое cherry pick ?

- Ответ
  Команда `git cherry-pick` используется для перенесения
  отдельных коммитов из одного места репозитория в другое, обычно между
  ветками разработки и обслуживания. Этот механизм отличается от привычных
  команд git merge и git rebase, которые переносят коммиты целыми
  цепочками.

---

### Какие пратики работы с гитом вы знаете? Форки

- Ответ

  Работа через форки принципиально отличается от других популярных методов организации командной разработки. Вместо того чтобы использовать один серверный репозиторий в качестве центральной кодовой базы, здесь каждый разработчик получает свой собственный репозиторий. Чаще всего эта модель применяется в общедоступных open source проектах.

  Основное преимущество forking workflow заключается в том, что все изменения вносятся без загрязнения истории проекта. Разработчики делают push в собственные репозитории, а доступ к центральному есть только у менеджера.

  Когда обновление готово к интеграции, программист делает pull-запрос в главный репозиторий, а менеджер одобряет и вносит его.

  В принципе какие сть форки:

  - central workflow - когда все сразу с мастер пушится
  - trunk based - есть 3 ветки: мастер, дев, фьечер.
    основные особенности такой разработки что ветки живут недолго, что есть флаги которыми можно выключить и включать фичи, код в мастере почти всегда готов к деплою даже если в нем есть недоработанные фичи, постоянное код ревью кода (ревью пару минут на микро изменения и мерж)
  - gitflow

  по подробнее почитать про trunk based development https://habr.com/ru/articles/519314/

---

### Что такое GitFlow?

- Ответ
  [Модель gitflow](https://proglib.io/p/git-github-gitflow/) использует две параллельные «долгие» ветки для хранения истории проекта: master и develop.
  - **Master** – это полностью готовое к релизу состояние со всеми пройденными тестами.
    - **Hotfix** – ветки обслуживания, или хотфиксы, которые
      используются для быстрых патчей. Они очень похожи на feature, но вместо
      develop-ветки базируются на master.
  - **Develop** – ветка, в которой объединяются и тестируются все отдельные разработки. После прохождения проверок они отправляются в master.
    - **Feature** – отдельная ветка для каждой новой функциональности, изменения из которой отправляются в develop.
      img https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%2022.png

---

## Terraform

### Отличие ansible и terraform

- Ответ

  **Terraform** - Предназначен для представления инфраструктуры как код и автоматизации ее развертывания.

  **Ansible** - Предназначен для автоматизации развертывания и конфигурации приложений.

  То есть Terraform используется что бы разворачивать инфраструктуру (виртуальные машины, сети, диски, и тп.).
  Ansible предназначен для работы с существующими ресурсами, чтобы устанавливать и настраивать окружение (программы, операционные системы) на этих виртуалках.

  Нюансы:
  Terraform отслеживает состояние и делает инкрементные изменения, что особенно полезно при работе с облачной инфраструктурой.
  Ansible не управляет состоянием, и каждая задача считается независимой.

  Нужно понимать, что это инструменты. И в ряде случаев с помощью Ansible равзвернуть инфраструктуру всё таки можно.
  Как и для терраформа написать провайдер, который будет делать что-то свое. Вопрос лишь в применимости инструментов.

---

### Что такое провайдер в terraform

- Ответ

  Это утилита, прослойка, которая позволяет Terraform взаимодействовать с определенным API облачного провадйера.

  Провайдеры используются для настройки и управления ресурсами, которые разворачиваются в облаке этого провайдера.

---

### Что такое ресурс в terraform

- Ответ

  Это какой то блок кода, который описывает объект в инфраструктуре. Каждый ресурс имеет свои какие то аргументы, свои параметры, свою конфигурацию. Ресурс имеет свой какой то уникальный идентификатор (ID, ARN и тд).

  Виртуальная машина, сеть, диск, порт, балансировщик и тд.

---

### Что такое tfstate

- Ответ

  Это файл, которй хранит определенное состяние инфраструктуры на момент последнего запуска.
  Используется для отслеживания состояния инфраструктуры терраформом.

---

### configure drift что такое

- Ответ

  Это ситуация, когда фактическое состояние инфраструктуры в облаке отличается от ожидаемого состояния, прописанного в terraform файлах.

  Может возникать при изменении ресурсов вне терраформа, либо правки tfstate файла вручную.

  Может привести к удалению ресурсов, либо привести к нежелательным изменениям.

---

### Как блокировать tfstate

- Ответ

  в AWS облаке tfstate блокируется с помощью dynamoDB.

  При создании DynamoDB в поле Primary key указывается значение LockID типа String.

  В коде это выглядит вот так:

  ```

    terraform {
      backend "s3" {
        bucket = "backet_name"
        encrypt = true
        key    = "dev/network/terraform.tfstate"
        region = "us-east-1"
        dynamodb_table = "terraform_state_block_DynamoDB"

      }
    }


  ```

  Посмотреть как это делается можно тут -> https://www.youtube.com/watch?v=R9so36Uob8c

---

### Как можно ресурс созданный в GUI перенести в код terraform

- Ответ

  можно использовать terraform import прописав сначала куда импортировать, а затем id ресурса который нужно импортировать

  Пример:

  ```bash

   terraform import aws_instance.instance_to_import  your_resource_id

  ```

  Либо можно в коде прописать секцию import указав id ресурса и куда импортировать

  ```

      import {
         id = "your_resource_id"
         to = aws_instance.instance_for_import
       }

  ```

  - После:

  1. terraform plan для того, что бы посмотреть как terraform будет импортировать ресурсы

  2. Потом Apply для того что бы импортировать ресурсы и обновить state file.

  - Можно прописать `terraform plan -generate-config-out=generated.tf` если в конфигурации нету ресурса для импорта и после = написать ваше название файла .tf

  Почитать поподробнее можно здесь -> https://developer.hashicorp.com/terraform/language/import

---

### Отличие contidion от look up

- Ответ

  - lookup это функция которая принимает словарь переменных, который мы пишем обычно в variable.tf файле и ключ значения которое хотим от туда взять

  функция с переменными выглядит как

  **X = lookup(map, key)**

  - Conditions это условия выбора какой либо переменной

  условие с переменными выглядит так

  **X = CONDITION ? IF_TRUE : IF_FALSE**

  Пример как это можно использовать в коде:

  ```

   #condition
   resource "aws_instance" "server" {
     instance_type = var.env == "prod" ? "t3.large" : "t3.micro"

   }

   #lookup
   variable "ec2_types" {
     default = {
       "prod" = "t3.large"
       "staging" = "t3.medium"
       "dev" = "t3.micro"
     }
   }

   resource "aws_instance" "default" {
     instance_type = lookup(var.ec2_types, "prod")
   }

  ```

---

### Ты накидал код в тераформе, запустил план, вышел. После этого твой коллега накидал свой код, выполнил план, вышел. далее тебе нужно зааплаить свою инфру, будут ли какие-то ошибки

- Ответ

  Нет, ведь при **terraform plan** файл tfstate не меняется, а только показывается как будет применяться новые изменения к текущей инфраструктуре.

---

### У вас есть 20 серверов, созданных с помощью Terraform, но вы хотите удалить один из них. Можно ли уничтожить один ресурс из нескольких ресурсов без правки в самих файлах?

- Ответ

  Да можно с помощью команды terraform destroy и флага --target

  ```bash

  terraform destroy -target=aws_instance.my_instance

  ```

---

### Какие есть best practice для ухаживания за tfstate file?

- Ответ

  - Хранить фалй удаленно, например в s3 backet, для обеспечения совместной работы
    и безопасности.
  - Блокирования состояния на время применения инфраструктуры, для того что бы предотвратить конфликтов между изменениями.
  - Ограничения доступа. Доступ к стейт файлу доступ мог получить только авторизованный пользователь.
  - Настройка автоматических бэкапов, для того что бы не потерять состояние инфры

---

### У вас есть несколько сред — dev, stage, prod для вашего приложения, и вы хотите использовать один и тот же код для всех этих сред. Как ты можешь это сделать?

- Ответ

  Есть два вариант как это можно сделать.

  Через модули:

  - Ты пишешь код инфраструктуры, в variable файл выносишь все нужные параметры, что бы их потом можно было заменить, в outputs файл выносишь все нужные выходные данные.

  - Создаешь рядом с папкой с модулем создаешь уже папку проекта с папками под каждое окружение.
    В них уже создаешь условно файлик main.tf и в нем прописываешь блок кода module, и в коде проекта в среде прод этот блок кода может выглядить как:

    ```

        module "vpc_prod" {
            source     = "../../modules/vpc_and_network"
            env        = "production"
            cidr_block = "10.100.1.0/24"

            publick_cidr_subntet = [
              "10.100.12.0/24",
              "10.100.13.0/24",
              "10.100.14.0/24",
            ]
            private_cidr_subnets = [
              "10.100.21.0/24",
              "10.100.22.0/24"
            ]
        }
       #так же это могут быть модули, которые хранятся удаленно

    ```

  Структура папок может выглядить вот так:

  ./imgs/not_best_practice.png

  Env по папкам это часто используется, но на деле это противоречит DRY.
  Тут в качестве бест практис лучше иметь конфиги террагрунта под каждый env со своими переменными под окружени.

  Структура папок по бестпрактис может выглядить вот так:

  /imgs/folder_struct_best_practice.png

  - Есть метод через workspace который почти нигде не используется.

  - Так же в качестве best practice разграничение по аккам используется, с точки зрения тф нужно будет деплоиться на разных акках

  В коде это будет выглядить как:

  ```

      provider "aws" {
          region = "eu-central-2"


          assume_role {
            role_arn     = "arn:aws:iam::1234567890:role/RemoteAdministrator"
            session_name = "terraform session"

      }

  ```

  На аккаунте на котором будет происходить деплой должна быть соответсвующая роль которая позволяет это делать, либо нужно вводить access_key и secret_key

---

## Рабочий процесс

### Что такое SLO, SLA, SLI?

- Ответ

  Кратко
  **SLI** - непосредственно замеряемые метрики
  **SLO** - то, к чему стремимся, чего хотим достичь
  **SLA** - о чем договорились, обязательства

  Для начала стоит отметить что все эти понятия взаимосвязаны.

  - **SLA (Service Level Agreement)** - это соглашение\контракт\регламент между поставщиком услуг и конечным пользователем.
    И в рамках этого контракта оговаривается уровень доступности услуги на который можно рассчитывать.
    Также оговариваются обязательства и последствия их невыполнения.

    Примеры:  
    Если в течение месяца не выполнялись бэкапы, то компенсируется целиком стоимость этой услуги.  
    Если доступность виртуальных машин падает ниже n-% процентов, то компенсация в виде бонусных баллов за все часы простоя.

  - **SLO (Service Level Objective)** - это как будет оцениваться качество сервиса. Каких показателей собираемся достигать.
    Иными словами это измеримая вещь, через призму которой можно понять что стоит отслеживать и улучшать. Уме

    Примеры:
    Доступность виртуальных машин должна составлять 99,9% в месяц.  
    Время ответа api не должно превышать n-секунд\милисекунд.  
    Количество\коэффициент ошибок должен быть менее n-%

  - **SLI (Sevice Level Indicator)** - это непосредственно собираемая конкретная характеристика, метрика.
    Сколько были доступны виртуальные машины за месяц? Какой процент ответа апи? Какое количество ошибок?
    Всё, что может ответить на этот вопрос это всё про вот это.
    Эти значения могут быть усреднены, растянуты во времени, переведены в проценты.

    Примеры:
    Сбор метрик доступности главной страницы сайта.

    Или еще пример - https://steamstat.us/  
    Страничка, показывающая доступны ли сервера Steam.
    Но здесь стоит сделать ремарку - компании сами замеряют SLI средствами мониторинга.
    В данном случае это просто хороший наглядный пример.

    Статьи, которые помогли в понимании сути:
    https://etogeek.dev/posts/sli-slo-sla/  
    https://uptimerobot.com/blog/sla-slo-sli/
